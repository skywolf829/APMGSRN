Initializing dataset - reading D:\GitHub\DistributedINR\Code\Datasets\..\..\Data\Isotropic.nc
Feature grid shape: [1, 16, 64, 64, 64]
Training on cpu D:\GitHub\DistributedINR\Code\..\SavedModels\Supernova_Ryzen9_3900X_12core
[{'params': [Parameter containing:
tensor([[[[[8.8227e-01, 9.1500e-01, 3.8286e-01,  ..., 1.5873e-01,
            6.5418e-01, 3.2781e-01],
           [6.5321e-01, 3.9583e-01, 9.1470e-01,  ..., 2.0830e-01,
            3.2885e-01, 1.0536e-01],
           [9.1923e-01, 4.0077e-01, 9.3020e-01,  ..., 5.5349e-01,
            4.1167e-01, 3.5100e-01],
           ...,
           [1.4568e-01, 1.4993e-01, 3.2976e-01,  ..., 9.6244e-01,
            6.4003e-01, 7.4087e-01],
           [1.7087e-01, 5.7969e-01, 6.3399e-01,  ..., 6.8852e-01,
            2.4047e-01, 5.9558e-01],
           [9.1989e-01, 1.2470e-01, 3.5734e-01,  ..., 6.7520e-01,
            2.0579e-01, 5.0270e-01]],

          [[1.4578e-01, 9.0244e-01, 9.2169e-01,  ..., 1.8675e-01,
            6.3519e-01, 8.4307e-01],
           [9.5486e-01, 4.4349e-01, 6.9238e-01,  ..., 1.1683e-01,
            7.1601e-01, 5.4620e-01],
           [1.6156e-01, 1.0544e-01, 8.6136e-01,  ..., 4.5310e-01,
            4.7363e-01, 9.4479e-01],
           ...,
           [4.3094e-01, 3.9862e-01, 1.9068e-01,  ..., 9.4445e-01,
            2.8485e-01, 3.7764e-01],
           [7.9479e-01, 6.8546e-01, 1.0094e-01,  ..., 6.1467e-01,
            7.7474e-01, 2.3228e-01],
           [5.8397e-01, 9.7948e-01, 3.2770e-01,  ..., 3.5492e-01,
            1.2626e-01, 1.2804e-01]],

          [[5.0270e-01, 4.1946e-01, 8.8927e-01,  ..., 3.0836e-01,
            1.5671e-01, 7.8603e-01],
           [7.3097e-01, 9.3070e-01, 2.8470e-01,  ..., 8.4324e-01,
            8.3071e-01, 8.9699e-02],
           [7.0210e-01, 5.9667e-01, 7.7443e-01,  ..., 8.4849e-01,
            4.5201e-01, 4.0053e-02],
           ...,
           [5.4402e-01, 6.7857e-02, 6.5774e-01,  ..., 9.9475e-01,
            2.7908e-01, 4.1423e-01],
           [5.0951e-01, 1.2463e-01, 1.7259e-01,  ..., 9.8379e-02,
            3.2239e-01, 3.1245e-01],
           [3.6122e-01, 8.7058e-01, 4.7512e-01,  ..., 5.3684e-01,
            2.3886e-01, 2.0954e-01]],

          ...,

          [[5.0925e-01, 7.5767e-01, 9.0053e-01,  ..., 3.9877e-01,
            1.2474e-01, 5.5376e-01],
           [9.9768e-01, 2.7489e-01, 5.6458e-01,  ..., 7.2669e-01,
            9.7901e-02, 9.6234e-01],
           [7.4547e-01, 1.3951e-01, 9.5826e-01,  ..., 8.2070e-01,
            2.9469e-01, 2.9131e-01],
           ...,
           [7.7552e-01, 6.8253e-01, 6.1187e-01,  ..., 4.6167e-01,
            2.2849e-01, 4.7623e-01],
           [7.8128e-01, 6.2212e-01, 9.1964e-01,  ..., 7.9353e-02,
            7.6258e-01, 4.5886e-01],
           [4.2244e-01, 3.3507e-01, 9.7651e-01,  ..., 8.7899e-01,
            5.5034e-01, 5.3804e-01]],

          [[8.8328e-01, 8.3709e-01, 9.7746e-01,  ..., 6.6611e-01,
            1.9192e-01, 4.4377e-02],
           [4.4934e-01, 5.2119e-01, 3.2580e-01,  ..., 7.4505e-01,
            4.3263e-01, 9.3497e-01],
           [4.0296e-01, 2.5299e-01, 6.9722e-01,  ..., 4.2474e-01,
            4.9258e-01, 3.7457e-01],
           ...,
           [1.3291e-01, 7.2627e-01, 3.3970e-01,  ..., 1.4784e-01,
            1.3562e-01, 8.4134e-01],
           [1.8202e-02, 2.9510e-01, 4.4053e-01,  ..., 1.4780e-01,
            3.0011e-01, 5.3778e-01],
           [7.9182e-01, 8.5937e-01, 4.0005e-01,  ..., 1.9745e-01,
            3.3537e-01, 5.0472e-02]],

          [[8.9626e-01, 1.5258e-01, 6.9833e-01,  ..., 1.8669e-01,
            8.0667e-01, 9.0288e-01],
           [3.2398e-01, 8.4379e-01, 3.3535e-01,  ..., 5.8688e-01,
            8.9153e-01, 8.3280e-02],
           [2.9930e-01, 4.4013e-01, 5.7692e-01,  ..., 6.5235e-02,
            9.7791e-02, 2.8944e-01],
           ...,
           [8.8411e-01, 4.9076e-01, 3.9163e-01,  ..., 4.5548e-01,
            7.2984e-01, 6.1496e-01],
           [4.2228e-01, 1.1172e-01, 4.9163e-01,  ..., 5.1787e-01,
            1.0932e-01, 3.7304e-01],
           [2.8996e-02, 2.0219e-01, 8.0038e-01,  ..., 7.0033e-02,
            6.8617e-01, 8.1567e-01]]],


         [[[6.8373e-01, 4.2741e-01, 3.0717e-01,  ..., 2.9161e-01,
            3.6842e-01, 3.6552e-01],
           [4.6443e-01, 1.4369e-01, 4.0590e-01,  ..., 3.7139e-01,
            2.6084e-01, 9.4573e-01],
           [6.4214e-01, 6.0789e-01, 4.3339e-01,  ..., 2.5420e-01,
            7.3628e-01, 5.3253e-01],
           ...,
           [2.1867e-01, 1.1202e-01, 3.5586e-01,  ..., 8.1628e-01,
            3.3485e-01, 4.2287e-01],
           [5.7023e-01, 7.5034e-01, 2.8352e-01,  ..., 5.2043e-01,
            1.6911e-02, 6.5596e-01],
           [5.1955e-01, 7.6017e-01, 8.9349e-01,  ..., 5.4750e-01,
            8.3552e-02, 4.3997e-01]],

          [[5.0186e-02, 6.5729e-01, 7.5280e-01,  ..., 6.6421e-01,
            2.0020e-01, 3.1095e-01],
           [2.0486e-01, 9.4479e-02, 3.0027e-02,  ..., 6.8694e-01,
            8.0119e-02, 2.1222e-01],
           [3.9136e-01, 5.0438e-01, 7.7757e-01,  ..., 5.4460e-01,
            5.2974e-01, 3.8212e-01],
           ...,
           [1.7691e-01, 5.7191e-01, 8.7203e-01,  ..., 6.2857e-01,
            6.1473e-01, 4.9241e-01],
           [5.4281e-01, 1.0047e-01, 5.3816e-01,  ..., 6.2230e-02,
            6.5354e-01, 1.6649e-01],
           [1.8637e-01, 4.0933e-01, 9.3275e-01,  ..., 6.3074e-02,
            3.2250e-02, 6.6866e-01]],

          [[1.5055e-01, 6.0415e-01, 9.0701e-01,  ..., 7.3080e-01,
            2.6740e-01, 2.7554e-01],
           [7.0159e-01, 5.9098e-01, 3.3854e-01,  ..., 4.5871e-01,
            6.6408e-01, 2.1093e-01],
           [8.2942e-01, 1.3869e-01, 7.7520e-01,  ..., 9.9412e-01,
            3.3942e-01, 9.4520e-01],
           ...,
           [7.8963e-01, 7.5614e-01, 2.3350e-01,  ..., 7.3306e-02,
            6.1889e-01, 3.7111e-01],
           [8.0901e-01, 3.0723e-01, 6.8683e-01,  ..., 6.8180e-01,
            6.5439e-01, 2.7435e-01],
           [4.7252e-01, 4.9189e-01, 9.7935e-02,  ..., 2.2435e-01,
            5.5411e-01, 3.1393e-01]],

          ...,

          [[8.7866e-01, 2.6891e-01, 7.8658e-01,  ..., 6.3718e-01,
            6.0604e-01, 1.7913e-01],
           [2.3317e-01, 6.2865e-01, 6.8686e-01,  ..., 2.1223e-01,
            9.4306e-01, 1.9123e-01],
           [1.4637e-01, 9.4896e-01, 2.1018e-01,  ..., 7.5598e-01,
            9.0954e-01, 7.8198e-01],
           ...,
           [9.5804e-01, 7.4177e-02, 9.7404e-02,  ..., 2.8512e-01,
            4.0225e-01, 4.2624e-01],
           [9.3197e-01, 4.8170e-01, 2.0807e-01,  ..., 6.9108e-01,
            2.8541e-01, 5.9702e-01],
           [2.5487e-02, 9.1671e-01, 8.6955e-01,  ..., 4.9760e-02,
            2.2623e-01, 1.8013e-01]],

          [[9.1133e-01, 5.8470e-01, 5.7405e-01,  ..., 8.7142e-01,
            6.4893e-02, 7.7132e-01],
           [8.5215e-01, 7.5039e-01, 9.1681e-01,  ..., 2.3306e-01,
            5.5441e-01, 7.7676e-01],
           [9.3779e-02, 3.3367e-01, 1.5178e-01,  ..., 8.3682e-02,
            4.9435e-01, 7.9183e-02],
           ...,
           [1.1507e-01, 8.2200e-01, 8.1621e-01,  ..., 5.6714e-01,
            5.0122e-01, 7.6287e-01],
           [7.7549e-01, 1.7170e-01, 7.5273e-01,  ..., 7.6698e-02,
            3.3625e-01, 3.5166e-02],
           [9.0460e-02, 1.0081e-01, 6.7929e-01,  ..., 5.5337e-01,
            5.6467e-01, 3.8555e-01]],

          [[5.3398e-01, 8.3465e-01, 9.5567e-01,  ..., 7.4842e-01,
            4.3587e-01, 9.3487e-01],
           [4.5168e-01, 8.2727e-01, 7.2432e-01,  ..., 2.2651e-01,
            3.0134e-02, 1.6034e-01],
           [6.4708e-01, 7.9718e-01, 6.3876e-01,  ..., 5.9272e-01,
            9.5239e-01, 5.9070e-01],
           ...,
           [6.3716e-01, 2.7239e-01, 2.3362e-01,  ..., 5.2336e-01,
            9.6739e-01, 2.6373e-01],
           [2.9006e-01, 1.9483e-01, 4.9077e-01,  ..., 9.8197e-02,
            5.0384e-01, 2.2017e-01],
           [3.9739e-01, 6.7127e-01, 9.7941e-01,  ..., 2.4673e-01,
            9.2878e-01, 6.4786e-01]]],


         [[[9.0671e-01, 7.6753e-01, 3.1797e-01,  ..., 8.9178e-01,
            8.2069e-01, 8.0955e-01],
           [5.5282e-01, 8.3475e-01, 7.4129e-01,  ..., 6.4965e-01,
            3.5737e-01, 1.4058e-01],
           [1.7799e-01, 5.9615e-01, 4.2643e-01,  ..., 4.7397e-01,
            6.8500e-01, 8.7435e-02],
           ...,
           [5.4947e-01, 3.0175e-01, 1.6675e-01,  ..., 7.6845e-02,
            3.2953e-01, 1.4530e-01],
           [7.3521e-01, 3.9358e-02, 8.6426e-01,  ..., 4.0332e-01,
            9.0235e-02, 6.2517e-01],
           [9.5837e-01, 3.4766e-01, 4.9440e-01,  ..., 8.0098e-02,
            5.1558e-01, 3.8923e-01]],

          [[4.5719e-01, 4.5272e-02, 1.6333e-01,  ..., 2.9683e-01,
            8.9860e-01, 9.2839e-01],
           [9.6776e-02, 4.2870e-01, 3.6301e-01,  ..., 7.1574e-02,
            5.7513e-01, 1.9891e-01],
           [8.8215e-01, 3.5218e-01, 8.9971e-01,  ..., 8.5428e-01,
            4.1162e-01, 8.8868e-01],
           ...,
           [8.6828e-01, 5.8013e-01, 1.4717e-01,  ..., 1.1756e-01,
            5.4112e-01, 4.7625e-02],
           [2.5785e-01, 6.9526e-01, 8.2785e-01,  ..., 4.0774e-01,
            9.3290e-02, 7.3068e-01],
           [5.8337e-01, 4.1481e-01, 2.9406e-01,  ..., 1.8782e-01,
            1.5556e-01, 6.2854e-01]],

          [[3.3135e-01, 8.1716e-01, 6.9723e-01,  ..., 2.9562e-01,
            8.6796e-01, 8.2621e-01],
           [1.9011e-03, 4.5412e-01, 5.9244e-01,  ..., 3.8125e-01,
            8.5793e-01, 4.5647e-01],
           [8.4570e-03, 4.5153e-01, 6.3672e-01,  ..., 9.3849e-01,
            5.1756e-01, 1.7229e-01],
           ...,
           [7.0744e-01, 2.1467e-01, 5.6309e-01,  ..., 9.5289e-01,
            5.7771e-02, 5.8303e-01],
           [5.6961e-01, 1.0190e-01, 7.2952e-01,  ..., 6.2602e-01,
            9.0852e-01, 4.4426e-03],
           [5.9573e-03, 7.1349e-01, 7.7155e-01,  ..., 3.6104e-01,
            2.8495e-02, 8.3027e-01]],

          ...,

          [[6.9872e-01, 9.9621e-01, 1.2145e-01,  ..., 9.7785e-01,
            5.1622e-01, 1.8325e-01],
           [9.9871e-01, 3.2815e-01, 2.7923e-01,  ..., 1.7274e-01,
            4.8153e-01, 1.5907e-01],
           [9.9970e-02, 3.2073e-01, 1.5653e-01,  ..., 8.0492e-01,
            1.2539e-01, 5.2912e-01],
           ...,
           [3.5179e-01, 3.8087e-01, 2.4628e-01,  ..., 7.8081e-01,
            5.1332e-02, 4.2589e-01],
           [8.2140e-01, 4.7344e-01, 1.7839e-01,  ..., 3.9035e-01,
            8.6526e-01, 7.7430e-01],
           [2.8253e-01, 7.6286e-01, 1.7606e-01,  ..., 9.3864e-01,
            8.4018e-01, 3.3880e-01]],

          [[2.7066e-01, 4.9521e-01, 9.5455e-01,  ..., 8.9757e-01,
            4.5441e-01, 3.8739e-01],
           [3.8148e-01, 2.3918e-01, 2.1107e-01,  ..., 8.2055e-02,
            8.0725e-01, 5.8540e-01],
           [5.5760e-01, 2.7138e-01, 9.9149e-01,  ..., 9.9377e-01,
            7.7652e-01, 3.2358e-01],
           ...,
           [6.7429e-01, 7.6148e-01, 1.1875e-01,  ..., 6.1765e-01,
            5.4425e-01, 4.6001e-01],
           [6.3148e-01, 8.8955e-02, 6.3427e-01,  ..., 6.7216e-01,
            3.5132e-01, 7.9522e-01],
           [5.6176e-01, 6.2132e-01, 2.0199e-01,  ..., 7.7650e-01,
            1.2430e-01, 9.2707e-01]],

          [[5.8415e-01, 5.8017e-01, 2.7841e-01,  ..., 2.8863e-01,
            8.5353e-01, 8.5933e-01],
           [6.9089e-01, 9.2124e-01, 4.5908e-01,  ..., 4.6924e-01,
            4.0149e-01, 2.2067e-01],
           [6.8186e-01, 3.5344e-01, 1.4118e-01,  ..., 7.6997e-01,
            5.1395e-01, 2.4947e-01],
           ...,
           [6.9541e-01, 3.4319e-01, 9.0111e-01,  ..., 3.5179e-01,
            3.6928e-02, 2.6978e-01],
           [6.0770e-01, 3.2464e-01, 4.9653e-02,  ..., 3.8432e-01,
            8.9736e-01, 5.8337e-03],
           [8.9727e-01, 3.7222e-01, 2.8714e-01,  ..., 6.1205e-01,
            8.9789e-01, 6.5129e-01]]],


         ...,


         [[[5.5872e-02, 1.2943e-02, 7.0736e-01,  ..., 6.6044e-01,
            6.5763e-01, 1.3030e-01],
           [8.7378e-01, 9.7296e-01, 2.2538e-02,  ..., 8.6265e-01,
            3.3524e-01, 5.4718e-01],
           [6.7254e-01, 1.2344e-01, 5.5226e-02,  ..., 4.3658e-01,
            3.3612e-01, 5.1776e-01],
           ...,
           [8.1700e-01, 5.5365e-01, 8.4554e-01,  ..., 4.1452e-02,
            5.0624e-01, 6.8317e-01],
           [2.9753e-01, 1.3056e-01, 1.7458e-01,  ..., 2.0520e-01,
            3.5738e-01, 9.4739e-01],
           [9.5697e-01, 8.9532e-01, 4.9331e-01,  ..., 7.9852e-01,
            6.8756e-01, 6.5926e-01]],

          [[5.4512e-01, 6.4674e-01, 4.1747e-01,  ..., 4.2506e-01,
            6.7710e-01, 7.1979e-01],
           [2.1573e-01, 3.1550e-01, 3.5756e-01,  ..., 9.2457e-02,
            9.7169e-01, 3.9275e-01],
           [3.9868e-01, 3.9563e-01, 5.4874e-01,  ..., 2.0583e-01,
            8.7610e-01, 2.8284e-02],
           ...,
           [6.5244e-01, 4.3783e-01, 6.7044e-01,  ..., 9.8110e-01,
            7.5473e-01, 6.9027e-01],
           [3.1618e-01, 1.6888e-01, 8.1186e-01,  ..., 7.3624e-01,
            1.3818e-01, 2.4233e-01],
           [7.6977e-01, 1.2329e-01, 3.6675e-02,  ..., 5.0716e-01,
            1.7698e-01, 2.0181e-01]],

          [[3.2328e-01, 7.0266e-01, 2.2179e-02,  ..., 4.9660e-01,
            9.9400e-01, 8.6201e-01],
           [1.1522e-01, 5.8567e-02, 7.1763e-01,  ..., 9.5457e-01,
            5.1437e-01, 5.2900e-01],
           [7.5700e-01, 9.7499e-01, 5.6805e-01,  ..., 5.6714e-01,
            8.2318e-01, 5.1050e-01],
           ...,
           [2.5306e-01, 3.4941e-01, 3.9886e-01,  ..., 4.0642e-01,
            9.1307e-01, 7.2807e-01],
           [3.1385e-01, 2.4345e-01, 2.2701e-02,  ..., 8.3784e-01,
            5.6965e-01, 3.8357e-01],
           [5.5912e-01, 4.8713e-01, 4.6547e-01,  ..., 4.5576e-01,
            2.4286e-01, 2.4569e-01]],

          ...,

          [[1.4395e-03, 8.3844e-01, 9.1620e-01,  ..., 6.5034e-01,
            9.2640e-01, 9.2632e-01],
           [8.5639e-01, 3.9071e-01, 5.5674e-01,  ..., 3.5923e-02,
            2.6820e-01, 6.5466e-02],
           [4.1755e-01, 4.4107e-01, 4.1245e-01,  ..., 2.4818e-01,
            4.4112e-01, 2.5030e-01],
           ...,
           [1.4943e-01, 5.1158e-01, 4.8989e-01,  ..., 5.1545e-01,
            6.7662e-01, 4.2757e-01],
           [1.1277e-01, 7.0807e-01, 3.5882e-01,  ..., 4.0273e-01,
            4.1870e-02, 8.7185e-01],
           [8.2821e-02, 7.6708e-01, 8.1901e-01,  ..., 6.2891e-01,
            1.8079e-01, 3.4145e-01]],

          [[3.0933e-01, 6.8158e-01, 4.0226e-01,  ..., 7.6873e-01,
            9.4941e-01, 1.0994e-01],
           [1.1090e-01, 6.8492e-01, 9.9361e-01,  ..., 5.2802e-01,
            7.8034e-01, 5.9384e-01],
           [3.8957e-01, 3.5724e-01, 1.1953e-02,  ..., 3.2394e-01,
            3.9167e-01, 8.3645e-01],
           ...,
           [7.5583e-01, 7.3146e-01, 4.4723e-01,  ..., 5.4352e-01,
            6.9329e-01, 3.1153e-01],
           [7.2254e-01, 6.5960e-01, 8.9869e-01,  ..., 9.8679e-01,
            6.5071e-01, 7.9612e-01],
           [4.2433e-01, 1.2680e-01, 1.6892e-01,  ..., 7.3444e-01,
            1.9552e-01, 9.1675e-01]],

          [[2.3900e-01, 4.9944e-01, 6.0461e-01,  ..., 9.9159e-01,
            7.6931e-01, 2.6784e-01],
           [8.5789e-01, 7.0563e-01, 2.8497e-01,  ..., 4.1627e-01,
            6.5377e-01, 2.3352e-01],
           [5.8081e-01, 4.0095e-01, 9.7754e-01,  ..., 5.4644e-01,
            9.2141e-01, 3.8773e-01],
           ...,
           [8.7678e-02, 8.8587e-01, 6.3553e-01,  ..., 2.2069e-01,
            6.6917e-01, 1.5693e-01],
           [2.1394e-01, 7.0102e-01, 7.2379e-01,  ..., 7.9479e-01,
            2.1071e-01, 5.6361e-01],
           [8.7104e-01, 7.7276e-01, 7.1702e-01,  ..., 1.6998e-02,
            7.7909e-01, 4.1392e-01]]],


         [[[7.8803e-01, 7.8202e-01, 4.1429e-01,  ..., 5.3127e-01,
            7.2099e-01, 3.6652e-01],
           [1.5494e-01, 6.6163e-01, 4.1892e-01,  ..., 5.0312e-01,
            2.0430e-01, 1.3209e-01],
           [8.1054e-01, 3.2966e-02, 5.8504e-01,  ..., 6.2110e-02,
            8.9515e-01, 1.1781e-01],
           ...,
           [1.0655e-01, 8.1903e-01, 8.6421e-02,  ..., 9.9572e-01,
            2.2295e-01, 1.8089e-03],
           [1.9312e-01, 8.4423e-01, 3.7199e-02,  ..., 9.0296e-01,
            3.0476e-01, 4.3375e-01],
           [2.1041e-01, 8.0498e-01, 4.9459e-01,  ..., 6.5269e-01,
            5.3622e-01, 7.6110e-01]],

          [[1.7107e-01, 2.7219e-01, 7.2164e-01,  ..., 5.8045e-01,
            8.9776e-01, 4.9218e-01],
           [5.3583e-01, 9.7263e-01, 5.7404e-01,  ..., 5.8728e-01,
            5.5741e-01, 3.0180e-01],
           [1.7055e-01, 7.8879e-01, 4.1091e-01,  ..., 7.5156e-01,
            7.5840e-01, 4.8388e-01],
           ...,
           [4.7855e-01, 2.2791e-01, 6.2730e-01,  ..., 6.9149e-01,
            7.7846e-01, 3.2704e-01],
           [6.6143e-01, 2.6308e-01, 5.5712e-01,  ..., 8.8229e-01,
            7.5210e-01, 8.4482e-02],
           [3.7885e-02, 2.9857e-01, 7.1192e-01,  ..., 1.5321e-02,
            8.1692e-01, 2.6292e-01]],

          [[9.5090e-01, 7.8795e-01, 4.2431e-01,  ..., 7.7983e-01,
            3.7903e-01, 5.4773e-01],
           [7.9920e-01, 3.1296e-01, 5.6094e-01,  ..., 6.4781e-01,
            4.5279e-01, 9.3031e-01],
           [5.9350e-01, 7.4831e-02, 9.3202e-01,  ..., 7.2615e-01,
            7.5057e-01, 9.6161e-01],
           ...,
           [2.4121e-01, 6.3971e-01, 9.3839e-01,  ..., 6.5470e-01,
            4.2236e-01, 7.0762e-01],
           [5.8278e-01, 1.9311e-01, 8.8963e-02,  ..., 5.0539e-01,
            7.3738e-01, 6.3325e-01],
           [6.9950e-01, 6.4211e-01, 1.9066e-01,  ..., 4.1727e-02,
            7.0075e-01, 8.6985e-01]],

          ...,

          [[1.9699e-01, 7.5569e-01, 9.3878e-01,  ..., 2.9766e-01,
            1.8618e-01, 5.8819e-01],
           [4.8240e-01, 6.9762e-01, 9.3093e-01,  ..., 4.8199e-01,
            6.2467e-01, 5.7740e-01],
           [5.4538e-02, 9.3356e-01, 4.2848e-01,  ..., 3.6582e-01,
            1.0679e-01, 2.3547e-01],
           ...,
           [8.9514e-02, 5.0278e-01, 1.8799e-01,  ..., 4.2658e-01,
            9.7619e-01, 3.4050e-01],
           [2.8943e-01, 9.7660e-01, 9.3123e-01,  ..., 6.8154e-01,
            2.4101e-01, 3.4447e-01],
           [7.0508e-01, 7.9508e-01, 5.9420e-01,  ..., 5.5584e-01,
            3.2133e-01, 5.2553e-01]],

          [[4.7822e-01, 4.6526e-01, 3.4573e-01,  ..., 3.3161e-01,
            1.0501e-01, 5.9144e-01],
           [1.3589e-01, 2.0469e-01, 2.4458e-01,  ..., 1.8385e-01,
            9.4172e-01, 2.7829e-01],
           [2.6694e-01, 7.0708e-01, 9.1418e-01,  ..., 2.6497e-01,
            3.1152e-01, 5.2912e-01],
           ...,
           [6.4359e-01, 6.3259e-01, 8.9497e-01,  ..., 5.1852e-01,
            2.5621e-01, 1.0759e-01],
           [4.1794e-01, 7.6875e-01, 2.4336e-01,  ..., 4.7630e-01,
            1.5082e-01, 6.8154e-01],
           [8.8390e-01, 7.6690e-01, 6.8806e-01,  ..., 4.8947e-01,
            9.0174e-01, 6.0411e-01]],

          [[2.0316e-01, 6.2264e-01, 4.2175e-01,  ..., 1.6068e-01,
            1.3216e-01, 5.5374e-02],
           [2.2251e-02, 8.6265e-01, 7.4815e-01,  ..., 2.8368e-01,
            9.0593e-01, 4.2091e-01],
           [1.3628e-01, 6.3263e-02, 9.9789e-01,  ..., 1.8153e-01,
            4.4495e-01, 7.2255e-01],
           ...,
           [9.4575e-02, 7.7700e-01, 3.4049e-01,  ..., 7.5657e-01,
            5.3826e-01, 7.2874e-01],
           [4.4519e-02, 6.6717e-01, 6.8645e-01,  ..., 2.7428e-01,
            1.5848e-01, 3.5427e-01],
           [4.7487e-01, 5.6787e-02, 2.1199e-01,  ..., 8.9719e-01,
            3.4831e-01, 2.8214e-01]]],


         [[[8.9902e-01, 9.3305e-01, 9.7130e-01,  ..., 3.9220e-01,
            6.9158e-01, 8.4258e-01],
           [1.2222e-01, 1.7272e-01, 5.1484e-02,  ..., 5.2758e-01,
            6.8063e-01, 6.7816e-01],
           [1.5851e-01, 1.2155e-01, 5.4002e-01,  ..., 9.6250e-02,
            8.8495e-02, 8.2296e-01],
           ...,
           [4.9207e-01, 4.3834e-01, 6.3065e-01,  ..., 6.1086e-01,
            5.2765e-02, 4.6343e-02],
           [7.0974e-01, 8.5713e-01, 6.6541e-01,  ..., 7.5544e-01,
            5.6026e-01, 8.1439e-01],
           [4.5554e-01, 5.4633e-01, 2.5218e-01,  ..., 6.6071e-01,
            7.2722e-01, 6.5032e-01]],

          [[3.6506e-01, 1.8238e-01, 8.5193e-01,  ..., 4.4132e-01,
            6.1372e-01, 1.7773e-01],
           [5.2437e-01, 5.3307e-01, 2.5545e-01,  ..., 1.1428e-01,
            1.2691e-01, 9.9083e-01],
           [5.2224e-01, 5.4638e-01, 1.4608e-01,  ..., 2.2321e-01,
            3.5442e-01, 5.3208e-02],
           ...,
           [2.9909e-02, 4.8665e-01, 5.2455e-01,  ..., 9.9019e-01,
            8.3871e-01, 9.4216e-01],
           [4.2326e-01, 4.9399e-01, 3.2114e-01,  ..., 3.5326e-01,
            9.6933e-01, 9.7555e-01],
           [1.1301e-01, 8.4466e-01, 8.0344e-01,  ..., 8.3520e-01,
            4.1817e-01, 7.4792e-01]],

          [[4.5042e-01, 5.6036e-02, 3.0795e-01,  ..., 4.0474e-01,
            5.2395e-01, 3.0874e-01],
           [7.0481e-01, 7.8731e-01, 2.5987e-01,  ..., 1.9976e-01,
            4.4007e-01, 3.7637e-01],
           [8.8294e-02, 2.3088e-01, 3.4704e-01,  ..., 2.5609e-01,
            5.7863e-01, 4.1964e-01],
           ...,
           [6.8184e-01, 5.2658e-01, 2.6166e-01,  ..., 9.1115e-01,
            4.3537e-01, 2.0516e-01],
           [8.8409e-01, 4.6004e-01, 9.7462e-01,  ..., 7.0559e-01,
            9.4412e-01, 1.0136e-01],
           [9.8330e-01, 7.3197e-01, 9.2321e-01,  ..., 3.0864e-01,
            8.1802e-02, 4.9697e-01]],

          ...,

          [[6.8829e-01, 9.5835e-01, 7.7917e-01,  ..., 5.7128e-01,
            9.2755e-01, 5.1177e-01],
           [8.2298e-01, 8.0106e-01, 9.4328e-02,  ..., 1.2608e-01,
            7.2458e-01, 5.4348e-04],
           [2.5063e-01, 6.6655e-01, 3.6928e-01,  ..., 3.9945e-01,
            2.4139e-01, 3.0121e-02],
           ...,
           [6.6275e-01, 6.2516e-01, 2.4132e-01,  ..., 9.5100e-01,
            8.1808e-01, 3.5203e-01],
           [2.9306e-02, 7.1798e-01, 2.7782e-02,  ..., 6.5583e-01,
            6.9724e-02, 5.7982e-01],
           [6.1776e-01, 7.3028e-01, 9.5202e-02,  ..., 6.6293e-01,
            3.4301e-01, 1.0975e-01]],

          [[2.6469e-02, 8.1629e-01, 1.1677e-01,  ..., 5.0439e-01,
            4.1922e-01, 6.5114e-02],
           [4.9825e-01, 2.8702e-02, 7.5633e-01,  ..., 3.7415e-01,
            3.5081e-02, 5.6784e-01],
           [2.7612e-01, 6.0988e-01, 3.2381e-01,  ..., 7.1255e-01,
            7.7058e-01, 3.0170e-01],
           ...,
           [4.2873e-01, 8.9128e-01, 5.6366e-01,  ..., 6.6913e-01,
            8.9242e-01, 5.4212e-01],
           [2.1705e-01, 6.7985e-01, 2.8496e-01,  ..., 2.8390e-01,
            2.9064e-01, 6.3419e-01],
           [6.9982e-01, 3.0616e-02, 6.4677e-01,  ..., 6.7084e-01,
            8.3714e-01, 9.7998e-03]],

          [[4.1534e-01, 8.2894e-01, 1.3103e-01,  ..., 4.7985e-01,
            4.5464e-01, 4.7163e-01],
           [5.8472e-01, 9.3248e-01, 9.1486e-01,  ..., 9.2609e-01,
            5.1239e-02, 8.9138e-01],
           [5.1976e-01, 9.2464e-01, 4.5088e-01,  ..., 6.8983e-01,
            5.1534e-01, 3.9186e-02],
           ...,
           [8.5152e-01, 6.8321e-01, 7.0400e-01,  ..., 2.6944e-01,
            1.1702e-01, 7.4579e-01],
           [1.7512e-01, 9.9310e-01, 9.0704e-01,  ..., 4.5771e-01,
            3.1928e-01, 8.3025e-01],
           [9.8098e-01, 5.4959e-01, 9.6042e-01,  ..., 3.8044e-01,
            8.7090e-01, 6.8667e-01]]]]], requires_grad=True), Parameter containing:
tensor([[ 0.0284, -0.0805,  0.0047,  ...,  0.0659,  0.1194, -0.0836],
        [-0.0067,  0.0670,  0.1536,  ...,  0.0257,  0.0415, -0.0328],
        [-0.2134,  0.2072, -0.2593,  ..., -0.1821, -0.1084,  0.0227],
        ...,
        [ 0.1097,  0.0911, -0.0323,  ..., -0.1718,  0.1225,  0.0887],
        [ 0.1768, -0.0787, -0.1276,  ...,  0.1742,  0.0333, -0.0969],
        [-0.2173, -0.0787, -0.0275,  ..., -0.1170,  0.0209,  0.0939]],
       requires_grad=True), Parameter containing:
tensor([ 0.0242,  0.1247,  0.1318,  0.1299, -0.0056, -0.1371, -0.0772,  0.0695,
        -0.0916,  0.0095,  0.0568, -0.1197, -0.0007, -0.0106,  0.0523, -0.0456,
         0.0331,  0.0925,  0.0592,  0.0230,  0.0328,  0.0391,  0.0383, -0.0315,
        -0.0043, -0.1015, -0.0228,  0.0049, -0.0990, -0.0849,  0.0119, -0.0621,
        -0.0849,  0.0108,  0.1219, -0.1127, -0.1149, -0.1287, -0.0637,  0.1013,
        -0.0246,  0.1173, -0.0064, -0.0119, -0.0706,  0.1184, -0.0186, -0.0269,
         0.0819, -0.1379,  0.0796,  0.0694, -0.0903,  0.0525, -0.0299,  0.0361,
        -0.1009,  0.1313,  0.0941,  0.0250,  0.1078, -0.1108, -0.0341, -0.0403],
       requires_grad=True), Parameter containing:
tensor([[-0.0571, -0.0712,  0.0355,  ...,  0.0685, -0.0431, -0.1355],
        [ 0.2420,  0.1844, -0.1659,  ..., -0.1731, -0.1410, -0.0265],
        [ 0.0863,  0.1555,  0.1119,  ...,  0.1525, -0.1144,  0.0420],
        ...,
        [-0.1349, -0.0016,  0.2157,  ..., -0.0259, -0.0456, -0.0750],
        [ 0.2253,  0.0403, -0.1738,  ..., -0.3090, -0.0639, -0.1282],
        [-0.3429, -0.1362,  0.0774,  ...,  0.0184,  0.0779, -0.1587]],
       requires_grad=True), Parameter containing:
tensor([ 0.0143, -0.0591,  0.0617,  0.1087,  0.1215, -0.0666, -0.0284,  0.0635,
         0.0777,  0.0660,  0.0053,  0.0035,  0.0677,  0.0790, -0.0641, -0.1024,
         0.0133, -0.1037,  0.0867,  0.0103,  0.0788, -0.1046,  0.1119, -0.1135,
         0.0484,  0.0871,  0.0964, -0.1039, -0.0931,  0.0294,  0.0099,  0.0336,
         0.0837,  0.0230,  0.0878,  0.1142,  0.1129, -0.0925, -0.0799, -0.0276,
         0.1195,  0.1005,  0.1147,  0.0089,  0.0920, -0.1112,  0.0497,  0.1099,
         0.0924, -0.0765,  0.0228, -0.0191, -0.0102, -0.1172,  0.0016,  0.0023,
         0.0336,  0.0624,  0.0242, -0.1170, -0.0187, -0.0653, -0.0361,  0.0359],
       requires_grad=True), Parameter containing:
tensor([[ 0.0687,  0.0827,  0.1400,  ..., -0.1291, -0.0560, -0.2654],
        [-0.0222, -0.1002,  0.0518,  ...,  0.1707, -0.1362,  0.0176],
        [-0.0187,  0.0137,  0.0740,  ...,  0.0858, -0.1017, -0.0352],
        ...,
        [-0.0814, -0.1625, -0.0560,  ...,  0.0241,  0.0956, -0.0702],
        [-0.0462, -0.0350,  0.0634,  ...,  0.2153,  0.0296, -0.0070],
        [-0.0754,  0.2645, -0.0599,  ..., -0.2452,  0.0914, -0.1148]],
       requires_grad=True), Parameter containing:
tensor([ 0.0032, -0.0198,  0.0356, -0.0927,  0.0050,  0.1194, -0.1014,  0.0517,
         0.0818,  0.0587, -0.1110,  0.0752, -0.0432, -0.0555,  0.0822,  0.0794,
         0.1020,  0.0116, -0.0504, -0.0757, -0.0038,  0.1038, -0.0345,  0.0267,
        -0.0629,  0.0969,  0.0833, -0.0968,  0.0992, -0.0025,  0.0499,  0.1102,
         0.0624, -0.0211, -0.0750,  0.0672,  0.0537, -0.0142,  0.0814,  0.0935,
         0.0214, -0.1100,  0.0316,  0.0673,  0.0678, -0.0812, -0.0400, -0.0867,
        -0.0004, -0.0416,  0.0147,  0.1155,  0.0448,  0.0520,  0.0923, -0.0602,
         0.1192,  0.0777,  0.0723, -0.1097,  0.0619, -0.0037, -0.0518, -0.0455],
       requires_grad=True), Parameter containing:
tensor([[ 0.1829,  0.1444,  0.0173,  ..., -0.0735,  0.1066, -0.0132],
        [ 0.1651,  0.1035,  0.2942,  ...,  0.0011,  0.1358, -0.1651],
        [ 0.1319, -0.0044,  0.0775,  ..., -0.1324,  0.0613,  0.2898],
        ...,
        [ 0.2034,  0.1428,  0.1203,  ..., -0.0012, -0.0486,  0.1744],
        [ 0.0228,  0.0553,  0.0124,  ..., -0.1141, -0.1004, -0.1947],
        [-0.2472, -0.0309, -0.1959,  ..., -0.1060, -0.0470, -0.0526]],
       requires_grad=True), Parameter containing:
tensor([ 0.0554, -0.0990, -0.0198,  0.0272, -0.0566,  0.0223,  0.0063, -0.0265,
         0.1230, -0.0955,  0.0082,  0.0395,  0.0874,  0.1016, -0.0639,  0.0136,
         0.1026, -0.0845, -0.0602,  0.1157,  0.1181, -0.0901, -0.0079,  0.1143,
         0.0362, -0.0065,  0.0131,  0.0908,  0.0044, -0.0891,  0.0279,  0.1060,
         0.0434,  0.1202,  0.0771,  0.0826,  0.1115,  0.1159,  0.1169, -0.0558,
        -0.0569, -0.0315,  0.0168, -0.0020, -0.0829,  0.0482, -0.0004,  0.0627,
        -0.0587, -0.0222,  0.0026, -0.0578,  0.1043, -0.0221, -0.0541,  0.1036,
         0.0667,  0.0986,  0.0823, -0.0962, -0.0170, -0.0392,  0.0783,  0.1202],
       requires_grad=True), Parameter containing:
tensor([[ 0.2340, -0.1530,  0.0851,  ..., -0.0536,  0.0242,  0.0925],
        [ 0.0458,  0.0474, -0.0894,  ...,  0.0934,  0.0483,  0.1628],
        [-0.1515, -0.2116,  0.0281,  ..., -0.1212, -0.0904, -0.0319],
        ...,
        [-0.1350, -0.0020,  0.0561,  ...,  0.0411, -0.0275, -0.0554],
        [-0.1050, -0.1183, -0.0933,  ...,  0.2816, -0.0281, -0.0475],
        [ 0.0065,  0.0900, -0.0529,  ..., -0.1772, -0.0376,  0.0494]],
       requires_grad=True), Parameter containing:
tensor([-0.1058, -0.0884,  0.0122,  0.0885,  0.0534, -0.0756, -0.0249,  0.0102,
        -0.1158,  0.0146,  0.1028,  0.0093, -0.0768,  0.0767, -0.0060, -0.0138,
         0.1025,  0.0425, -0.0908,  0.0931,  0.0757,  0.0321, -0.1182,  0.1145,
        -0.0688,  0.0263,  0.0026, -0.0959, -0.1220, -0.0458, -0.1112,  0.0640,
        -0.1075, -0.1043, -0.1167,  0.0753,  0.0826,  0.0483,  0.0473, -0.0785,
        -0.0483, -0.0970, -0.0397, -0.0688, -0.1157, -0.0293, -0.0616, -0.0442,
         0.1090,  0.0526,  0.0592, -0.0560,  0.0680,  0.0934,  0.0474,  0.0153,
        -0.0449, -0.0928, -0.0899,  0.0269, -0.0459,  0.0215, -0.0288,  0.0178],
       requires_grad=True), Parameter containing:
tensor([[ 0.1178, -0.0974, -0.0418,  ...,  0.1506,  0.0411, -0.1337],
        [ 0.1565, -0.0630,  0.1820,  ...,  0.2869,  0.2699,  0.2654],
        [ 0.0114,  0.1034,  0.0941,  ...,  0.0405,  0.1072, -0.2320],
        ...,
        [ 0.1984, -0.1312,  0.0974,  ...,  0.0439,  0.1998, -0.0644],
        [-0.1087, -0.0079,  0.1910,  ..., -0.2090, -0.0961,  0.1409],
        [-0.1836,  0.2026, -0.1140,  ..., -0.0153,  0.0779, -0.0386]],
       requires_grad=True), Parameter containing:
tensor([-0.0997, -0.1149, -0.0257, -0.0250,  0.0456,  0.0609,  0.0111, -0.0485,
         0.0685, -0.0240, -0.0703,  0.1091,  0.0722, -0.1171,  0.0267,  0.1032,
        -0.0184,  0.0425, -0.0475, -0.0247,  0.0577, -0.0344,  0.1164, -0.0848,
         0.0607, -0.0617, -0.0587,  0.0895, -0.0062,  0.0061, -0.1043, -0.1096,
         0.1104,  0.0225, -0.1202,  0.1193, -0.0771,  0.0698, -0.0938,  0.0639,
        -0.1088,  0.0966, -0.0665, -0.0863,  0.0912,  0.0537,  0.0411, -0.1159,
        -0.0970, -0.1208, -0.0387,  0.0274, -0.1019, -0.0128, -0.0544, -0.1024,
        -0.0281, -0.0661, -0.1196,  0.0132, -0.0459, -0.0429, -0.0592, -0.0029],
       requires_grad=True), Parameter containing:
tensor([[-0.1313,  0.1611,  0.2957,  0.1891,  0.1249,  0.1013,  0.1684,  0.3334,
         -0.4433, -0.0285, -0.0218,  0.0793,  0.1057,  0.1527,  0.0020,  0.1537,
          0.0670,  0.0077,  0.1035, -0.1063, -0.2490, -0.2002, -0.2065,  0.0257,
         -0.2566,  0.0238,  0.1859, -0.0198, -0.2353,  0.0407, -0.3542, -0.1191,
         -0.2385,  0.1859,  0.0591,  0.1548, -0.0125, -0.0107,  0.1284,  0.2131,
         -0.1626, -0.3024,  0.1589,  0.1854,  0.2244,  0.0649, -0.0410,  0.2107,
         -0.0163, -0.1029,  0.0452,  0.2244, -0.0961, -0.2350,  0.3812, -0.0138,
          0.2476, -0.3121,  0.0281,  0.0990, -0.3670, -0.1365, -0.0599,  0.1271]],
       requires_grad=True), Parameter containing:
tensor([0.0100], requires_grad=True)], 'lr': 0.01, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': False, 'initial_lr': 0.01}][W C:\cb\pytorch_1000000000000\work\torch\csrc\profiler\kineto_shim.cpp:330] Profiler is not initialized: skipping step() invocation
STAGE:2022-11-07 16:28:23 4536:4808 C:\cb\pytorch_1000000000000\work\third_party\kineto\libkineto\src\ActivityProfilerController.cpp:294] Completed Stage: Warm Up
[W C:\cb\pytorch_1000000000000\work\c10\core\CPUAllocator.cpp:231] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event
STAGE:2022-11-07 16:28:24 4536:4808 C:\cb\pytorch_1000000000000\work\third_party\kineto\libkineto\src\ActivityProfilerController.cpp:300] Completed Stage: Collection
STAGE:2022-11-07 16:28:24 4536:4808 C:\cb\pytorch_1000000000000\work\third_party\kineto\libkineto\src\output_json.cpp:417] Completed Stage: Post Processing

Iteration 0/10000, Fitting loss:  0.36693 
Iteration 10/10000, Fitting loss:  0.08865 
Traceback (most recent call last):
  File "D:\GitHub\DistributedINR\Code\train.py", line 229, in <module>
    train(model, dataset, opt)
  File "D:\GitHub\DistributedINR\Code\train.py", line 118, in train
    logging(writer, iteration, {"Fitting loss": loss}, opt, dataset.data.shape[2:], dataset)
  File "D:\GitHub\DistributedINR\Code\train.py", line 60, in logging
    log_to_writer(iteration, losses, writer, opt)
  File "D:\GitHub\DistributedINR\Code\train.py", line 34, in log_to_writer
    GBytes = (torch.cuda.max_memory_allocated(device=opt['device']) \
  File "C:\Users\Sky\anaconda3\envs\DistINR\lib\site-packages\torch\cuda\memory.py", line 352, in max_memory_allocated
    return memory_stats(device=device).get("allocated_bytes.all.peak", 0)
  File "C:\Users\Sky\anaconda3\envs\DistINR\lib\site-packages\torch\cuda\memory.py", line 209, in memory_stats
    stats = memory_stats_as_nested_dict(device=device)
  File "C:\Users\Sky\anaconda3\envs\DistINR\lib\site-packages\torch\cuda\memory.py", line 220, in memory_stats_as_nested_dict
    device = _get_device_index(device, optional=True)
  File "C:\Users\Sky\anaconda3\envs\DistINR\lib\site-packages\torch\cuda\_utils.py", line 30, in _get_device_index
    raise ValueError('Expected a cuda device, but got: {}'.format(device))
ValueError: Expected a cuda device, but got: cpu
Initializing dataset - reading D:\GitHub\DistributedINR\Code\Datasets\..\..\Data\Supernova.nc
Feature grid shape: [1, 16, 64, 64, 64]
Training on cpu D:\GitHub\DistributedINR\Code\..\SavedModels\Supernova_Ryzen9_3900X_12core
[{'params': [Parameter containing:
tensor([[[[[8.8227e-01, 9.1500e-01, 3.8286e-01,  ..., 1.5873e-01,
            6.5418e-01, 3.2781e-01],
           [6.5321e-01, 3.9583e-01, 9.1470e-01,  ..., 2.0830e-01,
            3.2885e-01, 1.0536e-01],
           [9.1923e-01, 4.0077e-01, 9.3020e-01,  ..., 5.5349e-01,
            4.1167e-01, 3.5100e-01],
           ...,
           [1.4568e-01, 1.4993e-01, 3.2976e-01,  ..., 9.6244e-01,
            6.4003e-01, 7.4087e-01],
           [1.7087e-01, 5.7969e-01, 6.3399e-01,  ..., 6.8852e-01,
            2.4047e-01, 5.9558e-01],
           [9.1989e-01, 1.2470e-01, 3.5734e-01,  ..., 6.7520e-01,
            2.0579e-01, 5.0270e-01]],

          [[1.4578e-01, 9.0244e-01, 9.2169e-01,  ..., 1.8675e-01,
            6.3519e-01, 8.4307e-01],
           [9.5486e-01, 4.4349e-01, 6.9238e-01,  ..., 1.1683e-01,
            7.1601e-01, 5.4620e-01],
           [1.6156e-01, 1.0544e-01, 8.6136e-01,  ..., 4.5310e-01,
            4.7363e-01, 9.4479e-01],
           ...,
           [4.3094e-01, 3.9862e-01, 1.9068e-01,  ..., 9.4445e-01,
            2.8485e-01, 3.7764e-01],
           [7.9479e-01, 6.8546e-01, 1.0094e-01,  ..., 6.1467e-01,
            7.7474e-01, 2.3228e-01],
           [5.8397e-01, 9.7948e-01, 3.2770e-01,  ..., 3.5492e-01,
            1.2626e-01, 1.2804e-01]],

          [[5.0270e-01, 4.1946e-01, 8.8927e-01,  ..., 3.0836e-01,
            1.5671e-01, 7.8603e-01],
           [7.3097e-01, 9.3070e-01, 2.8470e-01,  ..., 8.4324e-01,
            8.3071e-01, 8.9699e-02],
           [7.0210e-01, 5.9667e-01, 7.7443e-01,  ..., 8.4849e-01,
            4.5201e-01, 4.0053e-02],
           ...,
           [5.4402e-01, 6.7857e-02, 6.5774e-01,  ..., 9.9475e-01,
            2.7908e-01, 4.1423e-01],
           [5.0951e-01, 1.2463e-01, 1.7259e-01,  ..., 9.8379e-02,
            3.2239e-01, 3.1245e-01],
           [3.6122e-01, 8.7058e-01, 4.7512e-01,  ..., 5.3684e-01,
            2.3886e-01, 2.0954e-01]],

          ...,

          [[5.0925e-01, 7.5767e-01, 9.0053e-01,  ..., 3.9877e-01,
            1.2474e-01, 5.5376e-01],
           [9.9768e-01, 2.7489e-01, 5.6458e-01,  ..., 7.2669e-01,
            9.7901e-02, 9.6234e-01],
           [7.4547e-01, 1.3951e-01, 9.5826e-01,  ..., 8.2070e-01,
            2.9469e-01, 2.9131e-01],
           ...,
           [7.7552e-01, 6.8253e-01, 6.1187e-01,  ..., 4.6167e-01,
            2.2849e-01, 4.7623e-01],
           [7.8128e-01, 6.2212e-01, 9.1964e-01,  ..., 7.9353e-02,
            7.6258e-01, 4.5886e-01],
           [4.2244e-01, 3.3507e-01, 9.7651e-01,  ..., 8.7899e-01,
            5.5034e-01, 5.3804e-01]],

          [[8.8328e-01, 8.3709e-01, 9.7746e-01,  ..., 6.6611e-01,
            1.9192e-01, 4.4377e-02],
           [4.4934e-01, 5.2119e-01, 3.2580e-01,  ..., 7.4505e-01,
            4.3263e-01, 9.3497e-01],
           [4.0296e-01, 2.5299e-01, 6.9722e-01,  ..., 4.2474e-01,
            4.9258e-01, 3.7457e-01],
           ...,
           [1.3291e-01, 7.2627e-01, 3.3970e-01,  ..., 1.4784e-01,
            1.3562e-01, 8.4134e-01],
           [1.8202e-02, 2.9510e-01, 4.4053e-01,  ..., 1.4780e-01,
            3.0011e-01, 5.3778e-01],
           [7.9182e-01, 8.5937e-01, 4.0005e-01,  ..., 1.9745e-01,
            3.3537e-01, 5.0472e-02]],

          [[8.9626e-01, 1.5258e-01, 6.9833e-01,  ..., 1.8669e-01,
            8.0667e-01, 9.0288e-01],
           [3.2398e-01, 8.4379e-01, 3.3535e-01,  ..., 5.8688e-01,
            8.9153e-01, 8.3280e-02],
           [2.9930e-01, 4.4013e-01, 5.7692e-01,  ..., 6.5235e-02,
            9.7791e-02, 2.8944e-01],
           ...,
           [8.8411e-01, 4.9076e-01, 3.9163e-01,  ..., 4.5548e-01,
            7.2984e-01, 6.1496e-01],
           [4.2228e-01, 1.1172e-01, 4.9163e-01,  ..., 5.1787e-01,
            1.0932e-01, 3.7304e-01],
           [2.8996e-02, 2.0219e-01, 8.0038e-01,  ..., 7.0033e-02,
            6.8617e-01, 8.1567e-01]]],


         [[[6.8373e-01, 4.2741e-01, 3.0717e-01,  ..., 2.9161e-01,
            3.6842e-01, 3.6552e-01],
           [4.6443e-01, 1.4369e-01, 4.0590e-01,  ..., 3.7139e-01,
            2.6084e-01, 9.4573e-01],
           [6.4214e-01, 6.0789e-01, 4.3339e-01,  ..., 2.5420e-01,
            7.3628e-01, 5.3253e-01],
           ...,
           [2.1867e-01, 1.1202e-01, 3.5586e-01,  ..., 8.1628e-01,
            3.3485e-01, 4.2287e-01],
           [5.7023e-01, 7.5034e-01, 2.8352e-01,  ..., 5.2043e-01,
            1.6911e-02, 6.5596e-01],
           [5.1955e-01, 7.6017e-01, 8.9349e-01,  ..., 5.4750e-01,
            8.3552e-02, 4.3997e-01]],

          [[5.0186e-02, 6.5729e-01, 7.5280e-01,  ..., 6.6421e-01,
            2.0020e-01, 3.1095e-01],
           [2.0486e-01, 9.4479e-02, 3.0027e-02,  ..., 6.8694e-01,
            8.0119e-02, 2.1222e-01],
           [3.9136e-01, 5.0438e-01, 7.7757e-01,  ..., 5.4460e-01,
            5.2974e-01, 3.8212e-01],
           ...,
           [1.7691e-01, 5.7191e-01, 8.7203e-01,  ..., 6.2857e-01,
            6.1473e-01, 4.9241e-01],
           [5.4281e-01, 1.0047e-01, 5.3816e-01,  ..., 6.2230e-02,
            6.5354e-01, 1.6649e-01],
           [1.8637e-01, 4.0933e-01, 9.3275e-01,  ..., 6.3074e-02,
            3.2250e-02, 6.6866e-01]],

          [[1.5055e-01, 6.0415e-01, 9.0701e-01,  ..., 7.3080e-01,
            2.6740e-01, 2.7554e-01],
           [7.0159e-01, 5.9098e-01, 3.3854e-01,  ..., 4.5871e-01,
            6.6408e-01, 2.1093e-01],
           [8.2942e-01, 1.3869e-01, 7.7520e-01,  ..., 9.9412e-01,
            3.3942e-01, 9.4520e-01],
           ...,
           [7.8963e-01, 7.5614e-01, 2.3350e-01,  ..., 7.3306e-02,
            6.1889e-01, 3.7111e-01],
           [8.0901e-01, 3.0723e-01, 6.8683e-01,  ..., 6.8180e-01,
            6.5439e-01, 2.7435e-01],
           [4.7252e-01, 4.9189e-01, 9.7935e-02,  ..., 2.2435e-01,
            5.5411e-01, 3.1393e-01]],

          ...,

          [[8.7866e-01, 2.6891e-01, 7.8658e-01,  ..., 6.3718e-01,
            6.0604e-01, 1.7913e-01],
           [2.3317e-01, 6.2865e-01, 6.8686e-01,  ..., 2.1223e-01,
            9.4306e-01, 1.9123e-01],
           [1.4637e-01, 9.4896e-01, 2.1018e-01,  ..., 7.5598e-01,
            9.0954e-01, 7.8198e-01],
           ...,
           [9.5804e-01, 7.4177e-02, 9.7404e-02,  ..., 2.8512e-01,
            4.0225e-01, 4.2624e-01],
           [9.3197e-01, 4.8170e-01, 2.0807e-01,  ..., 6.9108e-01,
            2.8541e-01, 5.9702e-01],
           [2.5487e-02, 9.1671e-01, 8.6955e-01,  ..., 4.9760e-02,
            2.2623e-01, 1.8013e-01]],

          [[9.1133e-01, 5.8470e-01, 5.7405e-01,  ..., 8.7142e-01,
            6.4893e-02, 7.7132e-01],
           [8.5215e-01, 7.5039e-01, 9.1681e-01,  ..., 2.3306e-01,
            5.5441e-01, 7.7676e-01],
           [9.3779e-02, 3.3367e-01, 1.5178e-01,  ..., 8.3682e-02,
            4.9435e-01, 7.9183e-02],
           ...,
           [1.1507e-01, 8.2200e-01, 8.1621e-01,  ..., 5.6714e-01,
            5.0122e-01, 7.6287e-01],
           [7.7549e-01, 1.7170e-01, 7.5273e-01,  ..., 7.6698e-02,
            3.3625e-01, 3.5166e-02],
           [9.0460e-02, 1.0081e-01, 6.7929e-01,  ..., 5.5337e-01,
            5.6467e-01, 3.8555e-01]],

          [[5.3398e-01, 8.3465e-01, 9.5567e-01,  ..., 7.4842e-01,
            4.3587e-01, 9.3487e-01],
           [4.5168e-01, 8.2727e-01, 7.2432e-01,  ..., 2.2651e-01,
            3.0134e-02, 1.6034e-01],
           [6.4708e-01, 7.9718e-01, 6.3876e-01,  ..., 5.9272e-01,
            9.5239e-01, 5.9070e-01],
           ...,
           [6.3716e-01, 2.7239e-01, 2.3362e-01,  ..., 5.2336e-01,
            9.6739e-01, 2.6373e-01],
           [2.9006e-01, 1.9483e-01, 4.9077e-01,  ..., 9.8197e-02,
            5.0384e-01, 2.2017e-01],
           [3.9739e-01, 6.7127e-01, 9.7941e-01,  ..., 2.4673e-01,
            9.2878e-01, 6.4786e-01]]],


         [[[9.0671e-01, 7.6753e-01, 3.1797e-01,  ..., 8.9178e-01,
            8.2069e-01, 8.0955e-01],
           [5.5282e-01, 8.3475e-01, 7.4129e-01,  ..., 6.4965e-01,
            3.5737e-01, 1.4058e-01],
           [1.7799e-01, 5.9615e-01, 4.2643e-01,  ..., 4.7397e-01,
            6.8500e-01, 8.7435e-02],
           ...,
           [5.4947e-01, 3.0175e-01, 1.6675e-01,  ..., 7.6845e-02,
            3.2953e-01, 1.4530e-01],
           [7.3521e-01, 3.9358e-02, 8.6426e-01,  ..., 4.0332e-01,
            9.0235e-02, 6.2517e-01],
           [9.5837e-01, 3.4766e-01, 4.9440e-01,  ..., 8.0098e-02,
            5.1558e-01, 3.8923e-01]],

          [[4.5719e-01, 4.5272e-02, 1.6333e-01,  ..., 2.9683e-01,
            8.9860e-01, 9.2839e-01],
           [9.6776e-02, 4.2870e-01, 3.6301e-01,  ..., 7.1574e-02,
            5.7513e-01, 1.9891e-01],
           [8.8215e-01, 3.5218e-01, 8.9971e-01,  ..., 8.5428e-01,
            4.1162e-01, 8.8868e-01],
           ...,
           [8.6828e-01, 5.8013e-01, 1.4717e-01,  ..., 1.1756e-01,
            5.4112e-01, 4.7625e-02],
           [2.5785e-01, 6.9526e-01, 8.2785e-01,  ..., 4.0774e-01,
            9.3290e-02, 7.3068e-01],
           [5.8337e-01, 4.1481e-01, 2.9406e-01,  ..., 1.8782e-01,
            1.5556e-01, 6.2854e-01]],

          [[3.3135e-01, 8.1716e-01, 6.9723e-01,  ..., 2.9562e-01,
            8.6796e-01, 8.2621e-01],
           [1.9011e-03, 4.5412e-01, 5.9244e-01,  ..., 3.8125e-01,
            8.5793e-01, 4.5647e-01],
           [8.4570e-03, 4.5153e-01, 6.3672e-01,  ..., 9.3849e-01,
            5.1756e-01, 1.7229e-01],
           ...,
           [7.0744e-01, 2.1467e-01, 5.6309e-01,  ..., 9.5289e-01,
            5.7771e-02, 5.8303e-01],
           [5.6961e-01, 1.0190e-01, 7.2952e-01,  ..., 6.2602e-01,
            9.0852e-01, 4.4426e-03],
           [5.9573e-03, 7.1349e-01, 7.7155e-01,  ..., 3.6104e-01,
            2.8495e-02, 8.3027e-01]],

          ...,

          [[6.9872e-01, 9.9621e-01, 1.2145e-01,  ..., 9.7785e-01,
            5.1622e-01, 1.8325e-01],
           [9.9871e-01, 3.2815e-01, 2.7923e-01,  ..., 1.7274e-01,
            4.8153e-01, 1.5907e-01],
           [9.9970e-02, 3.2073e-01, 1.5653e-01,  ..., 8.0492e-01,
            1.2539e-01, 5.2912e-01],
           ...,
           [3.5179e-01, 3.8087e-01, 2.4628e-01,  ..., 7.8081e-01,
            5.1332e-02, 4.2589e-01],
           [8.2140e-01, 4.7344e-01, 1.7839e-01,  ..., 3.9035e-01,
            8.6526e-01, 7.7430e-01],
           [2.8253e-01, 7.6286e-01, 1.7606e-01,  ..., 9.3864e-01,
            8.4018e-01, 3.3880e-01]],

          [[2.7066e-01, 4.9521e-01, 9.5455e-01,  ..., 8.9757e-01,
            4.5441e-01, 3.8739e-01],
           [3.8148e-01, 2.3918e-01, 2.1107e-01,  ..., 8.2055e-02,
            8.0725e-01, 5.8540e-01],
           [5.5760e-01, 2.7138e-01, 9.9149e-01,  ..., 9.9377e-01,
            7.7652e-01, 3.2358e-01],
           ...,
           [6.7429e-01, 7.6148e-01, 1.1875e-01,  ..., 6.1765e-01,
            5.4425e-01, 4.6001e-01],
           [6.3148e-01, 8.8955e-02, 6.3427e-01,  ..., 6.7216e-01,
            3.5132e-01, 7.9522e-01],
           [5.6176e-01, 6.2132e-01, 2.0199e-01,  ..., 7.7650e-01,
            1.2430e-01, 9.2707e-01]],

          [[5.8415e-01, 5.8017e-01, 2.7841e-01,  ..., 2.8863e-01,
            8.5353e-01, 8.5933e-01],
           [6.9089e-01, 9.2124e-01, 4.5908e-01,  ..., 4.6924e-01,
            4.0149e-01, 2.2067e-01],
           [6.8186e-01, 3.5344e-01, 1.4118e-01,  ..., 7.6997e-01,
            5.1395e-01, 2.4947e-01],
           ...,
           [6.9541e-01, 3.4319e-01, 9.0111e-01,  ..., 3.5179e-01,
            3.6928e-02, 2.6978e-01],
           [6.0770e-01, 3.2464e-01, 4.9653e-02,  ..., 3.8432e-01,
            8.9736e-01, 5.8337e-03],
           [8.9727e-01, 3.7222e-01, 2.8714e-01,  ..., 6.1205e-01,
            8.9789e-01, 6.5129e-01]]],


         ...,


         [[[5.5872e-02, 1.2943e-02, 7.0736e-01,  ..., 6.6044e-01,
            6.5763e-01, 1.3030e-01],
           [8.7378e-01, 9.7296e-01, 2.2538e-02,  ..., 8.6265e-01,
            3.3524e-01, 5.4718e-01],
           [6.7254e-01, 1.2344e-01, 5.5226e-02,  ..., 4.3658e-01,
            3.3612e-01, 5.1776e-01],
           ...,
           [8.1700e-01, 5.5365e-01, 8.4554e-01,  ..., 4.1452e-02,
            5.0624e-01, 6.8317e-01],
           [2.9753e-01, 1.3056e-01, 1.7458e-01,  ..., 2.0520e-01,
            3.5738e-01, 9.4739e-01],
           [9.5697e-01, 8.9532e-01, 4.9331e-01,  ..., 7.9852e-01,
            6.8756e-01, 6.5926e-01]],

          [[5.4512e-01, 6.4674e-01, 4.1747e-01,  ..., 4.2506e-01,
            6.7710e-01, 7.1979e-01],
           [2.1573e-01, 3.1550e-01, 3.5756e-01,  ..., 9.2457e-02,
            9.7169e-01, 3.9275e-01],
           [3.9868e-01, 3.9563e-01, 5.4874e-01,  ..., 2.0583e-01,
            8.7610e-01, 2.8284e-02],
           ...,
           [6.5244e-01, 4.3783e-01, 6.7044e-01,  ..., 9.8110e-01,
            7.5473e-01, 6.9027e-01],
           [3.1618e-01, 1.6888e-01, 8.1186e-01,  ..., 7.3624e-01,
            1.3818e-01, 2.4233e-01],
           [7.6977e-01, 1.2329e-01, 3.6675e-02,  ..., 5.0716e-01,
            1.7698e-01, 2.0181e-01]],

          [[3.2328e-01, 7.0266e-01, 2.2179e-02,  ..., 4.9660e-01,
            9.9400e-01, 8.6201e-01],
           [1.1522e-01, 5.8567e-02, 7.1763e-01,  ..., 9.5457e-01,
            5.1437e-01, 5.2900e-01],
           [7.5700e-01, 9.7499e-01, 5.6805e-01,  ..., 5.6714e-01,
            8.2318e-01, 5.1050e-01],
           ...,
           [2.5306e-01, 3.4941e-01, 3.9886e-01,  ..., 4.0642e-01,
            9.1307e-01, 7.2807e-01],
           [3.1385e-01, 2.4345e-01, 2.2701e-02,  ..., 8.3784e-01,
            5.6965e-01, 3.8357e-01],
           [5.5912e-01, 4.8713e-01, 4.6547e-01,  ..., 4.5576e-01,
            2.4286e-01, 2.4569e-01]],

          ...,

          [[1.4395e-03, 8.3844e-01, 9.1620e-01,  ..., 6.5034e-01,
            9.2640e-01, 9.2632e-01],
           [8.5639e-01, 3.9071e-01, 5.5674e-01,  ..., 3.5923e-02,
            2.6820e-01, 6.5466e-02],
           [4.1755e-01, 4.4107e-01, 4.1245e-01,  ..., 2.4818e-01,
            4.4112e-01, 2.5030e-01],
           ...,
           [1.4943e-01, 5.1158e-01, 4.8989e-01,  ..., 5.1545e-01,
            6.7662e-01, 4.2757e-01],
           [1.1277e-01, 7.0807e-01, 3.5882e-01,  ..., 4.0273e-01,
            4.1870e-02, 8.7185e-01],
           [8.2821e-02, 7.6708e-01, 8.1901e-01,  ..., 6.2891e-01,
            1.8079e-01, 3.4145e-01]],

          [[3.0933e-01, 6.8158e-01, 4.0226e-01,  ..., 7.6873e-01,
            9.4941e-01, 1.0994e-01],
           [1.1090e-01, 6.8492e-01, 9.9361e-01,  ..., 5.2802e-01,
            7.8034e-01, 5.9384e-01],
           [3.8957e-01, 3.5724e-01, 1.1953e-02,  ..., 3.2394e-01,
            3.9167e-01, 8.3645e-01],
           ...,
           [7.5583e-01, 7.3146e-01, 4.4723e-01,  ..., 5.4352e-01,
            6.9329e-01, 3.1153e-01],
           [7.2254e-01, 6.5960e-01, 8.9869e-01,  ..., 9.8679e-01,
            6.5071e-01, 7.9612e-01],
           [4.2433e-01, 1.2680e-01, 1.6892e-01,  ..., 7.3444e-01,
            1.9552e-01, 9.1675e-01]],

          [[2.3900e-01, 4.9944e-01, 6.0461e-01,  ..., 9.9159e-01,
            7.6931e-01, 2.6784e-01],
           [8.5789e-01, 7.0563e-01, 2.8497e-01,  ..., 4.1627e-01,
            6.5377e-01, 2.3352e-01],
           [5.8081e-01, 4.0095e-01, 9.7754e-01,  ..., 5.4644e-01,
            9.2141e-01, 3.8773e-01],
           ...,
           [8.7678e-02, 8.8587e-01, 6.3553e-01,  ..., 2.2069e-01,
            6.6917e-01, 1.5693e-01],
           [2.1394e-01, 7.0102e-01, 7.2379e-01,  ..., 7.9479e-01,
            2.1071e-01, 5.6361e-01],
           [8.7104e-01, 7.7276e-01, 7.1702e-01,  ..., 1.6998e-02,
            7.7909e-01, 4.1392e-01]]],


         [[[7.8803e-01, 7.8202e-01, 4.1429e-01,  ..., 5.3127e-01,
            7.2099e-01, 3.6652e-01],
           [1.5494e-01, 6.6163e-01, 4.1892e-01,  ..., 5.0312e-01,
            2.0430e-01, 1.3209e-01],
           [8.1054e-01, 3.2966e-02, 5.8504e-01,  ..., 6.2110e-02,
            8.9515e-01, 1.1781e-01],
           ...,
           [1.0655e-01, 8.1903e-01, 8.6421e-02,  ..., 9.9572e-01,
            2.2295e-01, 1.8089e-03],
           [1.9312e-01, 8.4423e-01, 3.7199e-02,  ..., 9.0296e-01,
            3.0476e-01, 4.3375e-01],
           [2.1041e-01, 8.0498e-01, 4.9459e-01,  ..., 6.5269e-01,
            5.3622e-01, 7.6110e-01]],

          [[1.7107e-01, 2.7219e-01, 7.2164e-01,  ..., 5.8045e-01,
            8.9776e-01, 4.9218e-01],
           [5.3583e-01, 9.7263e-01, 5.7404e-01,  ..., 5.8728e-01,
            5.5741e-01, 3.0180e-01],
           [1.7055e-01, 7.8879e-01, 4.1091e-01,  ..., 7.5156e-01,
            7.5840e-01, 4.8388e-01],
           ...,
           [4.7855e-01, 2.2791e-01, 6.2730e-01,  ..., 6.9149e-01,
            7.7846e-01, 3.2704e-01],
           [6.6143e-01, 2.6308e-01, 5.5712e-01,  ..., 8.8229e-01,
            7.5210e-01, 8.4482e-02],
           [3.7885e-02, 2.9857e-01, 7.1192e-01,  ..., 1.5321e-02,
            8.1692e-01, 2.6292e-01]],

          [[9.5090e-01, 7.8795e-01, 4.2431e-01,  ..., 7.7983e-01,
            3.7903e-01, 5.4773e-01],
           [7.9920e-01, 3.1296e-01, 5.6094e-01,  ..., 6.4781e-01,
            4.5279e-01, 9.3031e-01],
           [5.9350e-01, 7.4831e-02, 9.3202e-01,  ..., 7.2615e-01,
            7.5057e-01, 9.6161e-01],
           ...,
           [2.4121e-01, 6.3971e-01, 9.3839e-01,  ..., 6.5470e-01,
            4.2236e-01, 7.0762e-01],
           [5.8278e-01, 1.9311e-01, 8.8963e-02,  ..., 5.0539e-01,
            7.3738e-01, 6.3325e-01],
           [6.9950e-01, 6.4211e-01, 1.9066e-01,  ..., 4.1727e-02,
            7.0075e-01, 8.6985e-01]],

          ...,

          [[1.9699e-01, 7.5569e-01, 9.3878e-01,  ..., 2.9766e-01,
            1.8618e-01, 5.8819e-01],
           [4.8240e-01, 6.9762e-01, 9.3093e-01,  ..., 4.8199e-01,
            6.2467e-01, 5.7740e-01],
           [5.4538e-02, 9.3356e-01, 4.2848e-01,  ..., 3.6582e-01,
            1.0679e-01, 2.3547e-01],
           ...,
           [8.9514e-02, 5.0278e-01, 1.8799e-01,  ..., 4.2658e-01,
            9.7619e-01, 3.4050e-01],
           [2.8943e-01, 9.7660e-01, 9.3123e-01,  ..., 6.8154e-01,
            2.4101e-01, 3.4447e-01],
           [7.0508e-01, 7.9508e-01, 5.9420e-01,  ..., 5.5584e-01,
            3.2133e-01, 5.2553e-01]],

          [[4.7822e-01, 4.6526e-01, 3.4573e-01,  ..., 3.3161e-01,
            1.0501e-01, 5.9144e-01],
           [1.3589e-01, 2.0469e-01, 2.4458e-01,  ..., 1.8385e-01,
            9.4172e-01, 2.7829e-01],
           [2.6694e-01, 7.0708e-01, 9.1418e-01,  ..., 2.6497e-01,
            3.1152e-01, 5.2912e-01],
           ...,
           [6.4359e-01, 6.3259e-01, 8.9497e-01,  ..., 5.1852e-01,
            2.5621e-01, 1.0759e-01],
           [4.1794e-01, 7.6875e-01, 2.4336e-01,  ..., 4.7630e-01,
            1.5082e-01, 6.8154e-01],
           [8.8390e-01, 7.6690e-01, 6.8806e-01,  ..., 4.8947e-01,
            9.0174e-01, 6.0411e-01]],

          [[2.0316e-01, 6.2264e-01, 4.2175e-01,  ..., 1.6068e-01,
            1.3216e-01, 5.5374e-02],
           [2.2251e-02, 8.6265e-01, 7.4815e-01,  ..., 2.8368e-01,
            9.0593e-01, 4.2091e-01],
           [1.3628e-01, 6.3263e-02, 9.9789e-01,  ..., 1.8153e-01,
            4.4495e-01, 7.2255e-01],
           ...,
           [9.4575e-02, 7.7700e-01, 3.4049e-01,  ..., 7.5657e-01,
            5.3826e-01, 7.2874e-01],
           [4.4519e-02, 6.6717e-01, 6.8645e-01,  ..., 2.7428e-01,
            1.5848e-01, 3.5427e-01],
           [4.7487e-01, 5.6787e-02, 2.1199e-01,  ..., 8.9719e-01,
            3.4831e-01, 2.8214e-01]]],


         [[[8.9902e-01, 9.3305e-01, 9.7130e-01,  ..., 3.9220e-01,
            6.9158e-01, 8.4258e-01],
           [1.2222e-01, 1.7272e-01, 5.1484e-02,  ..., 5.2758e-01,
            6.8063e-01, 6.7816e-01],
           [1.5851e-01, 1.2155e-01, 5.4002e-01,  ..., 9.6250e-02,
            8.8495e-02, 8.2296e-01],
           ...,
           [4.9207e-01, 4.3834e-01, 6.3065e-01,  ..., 6.1086e-01,
            5.2765e-02, 4.6343e-02],
           [7.0974e-01, 8.5713e-01, 6.6541e-01,  ..., 7.5544e-01,
            5.6026e-01, 8.1439e-01],
           [4.5554e-01, 5.4633e-01, 2.5218e-01,  ..., 6.6071e-01,
            7.2722e-01, 6.5032e-01]],

          [[3.6506e-01, 1.8238e-01, 8.5193e-01,  ..., 4.4132e-01,
            6.1372e-01, 1.7773e-01],
           [5.2437e-01, 5.3307e-01, 2.5545e-01,  ..., 1.1428e-01,
            1.2691e-01, 9.9083e-01],
           [5.2224e-01, 5.4638e-01, 1.4608e-01,  ..., 2.2321e-01,
            3.5442e-01, 5.3208e-02],
           ...,
           [2.9909e-02, 4.8665e-01, 5.2455e-01,  ..., 9.9019e-01,
            8.3871e-01, 9.4216e-01],
           [4.2326e-01, 4.9399e-01, 3.2114e-01,  ..., 3.5326e-01,
            9.6933e-01, 9.7555e-01],
           [1.1301e-01, 8.4466e-01, 8.0344e-01,  ..., 8.3520e-01,
            4.1817e-01, 7.4792e-01]],

          [[4.5042e-01, 5.6036e-02, 3.0795e-01,  ..., 4.0474e-01,
            5.2395e-01, 3.0874e-01],
           [7.0481e-01, 7.8731e-01, 2.5987e-01,  ..., 1.9976e-01,
            4.4007e-01, 3.7637e-01],
           [8.8294e-02, 2.3088e-01, 3.4704e-01,  ..., 2.5609e-01,
            5.7863e-01, 4.1964e-01],
           ...,
           [6.8184e-01, 5.2658e-01, 2.6166e-01,  ..., 9.1115e-01,
            4.3537e-01, 2.0516e-01],
           [8.8409e-01, 4.6004e-01, 9.7462e-01,  ..., 7.0559e-01,
            9.4412e-01, 1.0136e-01],
           [9.8330e-01, 7.3197e-01, 9.2321e-01,  ..., 3.0864e-01,
            8.1802e-02, 4.9697e-01]],

          ...,

          [[6.8829e-01, 9.5835e-01, 7.7917e-01,  ..., 5.7128e-01,
            9.2755e-01, 5.1177e-01],
           [8.2298e-01, 8.0106e-01, 9.4328e-02,  ..., 1.2608e-01,
            7.2458e-01, 5.4348e-04],
           [2.5063e-01, 6.6655e-01, 3.6928e-01,  ..., 3.9945e-01,
            2.4139e-01, 3.0121e-02],
           ...,
           [6.6275e-01, 6.2516e-01, 2.4132e-01,  ..., 9.5100e-01,
            8.1808e-01, 3.5203e-01],
           [2.9306e-02, 7.1798e-01, 2.7782e-02,  ..., 6.5583e-01,
            6.9724e-02, 5.7982e-01],
           [6.1776e-01, 7.3028e-01, 9.5202e-02,  ..., 6.6293e-01,
            3.4301e-01, 1.0975e-01]],

          [[2.6469e-02, 8.1629e-01, 1.1677e-01,  ..., 5.0439e-01,
            4.1922e-01, 6.5114e-02],
           [4.9825e-01, 2.8702e-02, 7.5633e-01,  ..., 3.7415e-01,
            3.5081e-02, 5.6784e-01],
           [2.7612e-01, 6.0988e-01, 3.2381e-01,  ..., 7.1255e-01,
            7.7058e-01, 3.0170e-01],
           ...,
           [4.2873e-01, 8.9128e-01, 5.6366e-01,  ..., 6.6913e-01,
            8.9242e-01, 5.4212e-01],
           [2.1705e-01, 6.7985e-01, 2.8496e-01,  ..., 2.8390e-01,
            2.9064e-01, 6.3419e-01],
           [6.9982e-01, 3.0616e-02, 6.4677e-01,  ..., 6.7084e-01,
            8.3714e-01, 9.7998e-03]],

          [[4.1534e-01, 8.2894e-01, 1.3103e-01,  ..., 4.7985e-01,
            4.5464e-01, 4.7163e-01],
           [5.8472e-01, 9.3248e-01, 9.1486e-01,  ..., 9.2609e-01,
            5.1239e-02, 8.9138e-01],
           [5.1976e-01, 9.2464e-01, 4.5088e-01,  ..., 6.8983e-01,
            5.1534e-01, 3.9186e-02],
           ...,
           [8.5152e-01, 6.8321e-01, 7.0400e-01,  ..., 2.6944e-01,
            1.1702e-01, 7.4579e-01],
           [1.7512e-01, 9.9310e-01, 9.0704e-01,  ..., 4.5771e-01,
            3.1928e-01, 8.3025e-01],
           [9.8098e-01, 5.4959e-01, 9.6042e-01,  ..., 3.8044e-01,
            8.7090e-01, 6.8667e-01]]]]], requires_grad=True), Parameter containing:
tensor([[ 0.0284, -0.0805,  0.0047,  ...,  0.0659,  0.1194, -0.0836],
        [-0.0067,  0.0670,  0.1536,  ...,  0.0257,  0.0415, -0.0328],
        [-0.2134,  0.2072, -0.2593,  ..., -0.1821, -0.1084,  0.0227],
        ...,
        [ 0.1097,  0.0911, -0.0323,  ..., -0.1718,  0.1225,  0.0887],
        [ 0.1768, -0.0787, -0.1276,  ...,  0.1742,  0.0333, -0.0969],
        [-0.2173, -0.0787, -0.0275,  ..., -0.1170,  0.0209,  0.0939]],
       requires_grad=True), Parameter containing:
tensor([ 0.0242,  0.1247,  0.1318,  0.1299, -0.0056, -0.1371, -0.0772,  0.0695,
        -0.0916,  0.0095,  0.0568, -0.1197, -0.0007, -0.0106,  0.0523, -0.0456,
         0.0331,  0.0925,  0.0592,  0.0230,  0.0328,  0.0391,  0.0383, -0.0315,
        -0.0043, -0.1015, -0.0228,  0.0049, -0.0990, -0.0849,  0.0119, -0.0621,
        -0.0849,  0.0108,  0.1219, -0.1127, -0.1149, -0.1287, -0.0637,  0.1013,
        -0.0246,  0.1173, -0.0064, -0.0119, -0.0706,  0.1184, -0.0186, -0.0269,
         0.0819, -0.1379,  0.0796,  0.0694, -0.0903,  0.0525, -0.0299,  0.0361,
        -0.1009,  0.1313,  0.0941,  0.0250,  0.1078, -0.1108, -0.0341, -0.0403],
       requires_grad=True), Parameter containing:
tensor([[-0.0571, -0.0712,  0.0355,  ...,  0.0685, -0.0431, -0.1355],
        [ 0.2420,  0.1844, -0.1659,  ..., -0.1731, -0.1410, -0.0265],
        [ 0.0863,  0.1555,  0.1119,  ...,  0.1525, -0.1144,  0.0420],
        ...,
        [-0.1349, -0.0016,  0.2157,  ..., -0.0259, -0.0456, -0.0750],
        [ 0.2253,  0.0403, -0.1738,  ..., -0.3090, -0.0639, -0.1282],
        [-0.3429, -0.1362,  0.0774,  ...,  0.0184,  0.0779, -0.1587]],
       requires_grad=True), Parameter containing:
tensor([ 0.0143, -0.0591,  0.0617,  0.1087,  0.1215, -0.0666, -0.0284,  0.0635,
         0.0777,  0.0660,  0.0053,  0.0035,  0.0677,  0.0790, -0.0641, -0.1024,
         0.0133, -0.1037,  0.0867,  0.0103,  0.0788, -0.1046,  0.1119, -0.1135,
         0.0484,  0.0871,  0.0964, -0.1039, -0.0931,  0.0294,  0.0099,  0.0336,
         0.0837,  0.0230,  0.0878,  0.1142,  0.1129, -0.0925, -0.0799, -0.0276,
         0.1195,  0.1005,  0.1147,  0.0089,  0.0920, -0.1112,  0.0497,  0.1099,
         0.0924, -0.0765,  0.0228, -0.0191, -0.0102, -0.1172,  0.0016,  0.0023,
         0.0336,  0.0624,  0.0242, -0.1170, -0.0187, -0.0653, -0.0361,  0.0359],
       requires_grad=True), Parameter containing:
tensor([[ 0.0687,  0.0827,  0.1400,  ..., -0.1291, -0.0560, -0.2654],
        [-0.0222, -0.1002,  0.0518,  ...,  0.1707, -0.1362,  0.0176],
        [-0.0187,  0.0137,  0.0740,  ...,  0.0858, -0.1017, -0.0352],
        ...,
        [-0.0814, -0.1625, -0.0560,  ...,  0.0241,  0.0956, -0.0702],
        [-0.0462, -0.0350,  0.0634,  ...,  0.2153,  0.0296, -0.0070],
        [-0.0754,  0.2645, -0.0599,  ..., -0.2452,  0.0914, -0.1148]],
       requires_grad=True), Parameter containing:
tensor([ 0.0032, -0.0198,  0.0356, -0.0927,  0.0050,  0.1194, -0.1014,  0.0517,
         0.0818,  0.0587, -0.1110,  0.0752, -0.0432, -0.0555,  0.0822,  0.0794,
         0.1020,  0.0116, -0.0504, -0.0757, -0.0038,  0.1038, -0.0345,  0.0267,
        -0.0629,  0.0969,  0.0833, -0.0968,  0.0992, -0.0025,  0.0499,  0.1102,
         0.0624, -0.0211, -0.0750,  0.0672,  0.0537, -0.0142,  0.0814,  0.0935,
         0.0214, -0.1100,  0.0316,  0.0673,  0.0678, -0.0812, -0.0400, -0.0867,
        -0.0004, -0.0416,  0.0147,  0.1155,  0.0448,  0.0520,  0.0923, -0.0602,
         0.1192,  0.0777,  0.0723, -0.1097,  0.0619, -0.0037, -0.0518, -0.0455],
       requires_grad=True), Parameter containing:
tensor([[ 0.1829,  0.1444,  0.0173,  ..., -0.0735,  0.1066, -0.0132],
        [ 0.1651,  0.1035,  0.2942,  ...,  0.0011,  0.1358, -0.1651],
        [ 0.1319, -0.0044,  0.0775,  ..., -0.1324,  0.0613,  0.2898],
        ...,
        [ 0.2034,  0.1428,  0.1203,  ..., -0.0012, -0.0486,  0.1744],
        [ 0.0228,  0.0553,  0.0124,  ..., -0.1141, -0.1004, -0.1947],
        [-0.2472, -0.0309, -0.1959,  ..., -0.1060, -0.0470, -0.0526]],
       requires_grad=True), Parameter containing:
tensor([ 0.0554, -0.0990, -0.0198,  0.0272, -0.0566,  0.0223,  0.0063, -0.0265,
         0.1230, -0.0955,  0.0082,  0.0395,  0.0874,  0.1016, -0.0639,  0.0136,
         0.1026, -0.0845, -0.0602,  0.1157,  0.1181, -0.0901, -0.0079,  0.1143,
         0.0362, -0.0065,  0.0131,  0.0908,  0.0044, -0.0891,  0.0279,  0.1060,
         0.0434,  0.1202,  0.0771,  0.0826,  0.1115,  0.1159,  0.1169, -0.0558,
        -0.0569, -0.0315,  0.0168, -0.0020, -0.0829,  0.0482, -0.0004,  0.0627,
        -0.0587, -0.0222,  0.0026, -0.0578,  0.1043, -0.0221, -0.0541,  0.1036,
         0.0667,  0.0986,  0.0823, -0.0962, -0.0170, -0.0392,  0.0783,  0.1202],
       requires_grad=True), Parameter containing:
tensor([[ 0.2340, -0.1530,  0.0851,  ..., -0.0536,  0.0242,  0.0925],
        [ 0.0458,  0.0474, -0.0894,  ...,  0.0934,  0.0483,  0.1628],
        [-0.1515, -0.2116,  0.0281,  ..., -0.1212, -0.0904, -0.0319],
        ...,
        [-0.1350, -0.0020,  0.0561,  ...,  0.0411, -0.0275, -0.0554],
        [-0.1050, -0.1183, -0.0933,  ...,  0.2816, -0.0281, -0.0475],
        [ 0.0065,  0.0900, -0.0529,  ..., -0.1772, -0.0376,  0.0494]],
       requires_grad=True), Parameter containing:
tensor([-0.1058, -0.0884,  0.0122,  0.0885,  0.0534, -0.0756, -0.0249,  0.0102,
        -0.1158,  0.0146,  0.1028,  0.0093, -0.0768,  0.0767, -0.0060, -0.0138,
         0.1025,  0.0425, -0.0908,  0.0931,  0.0757,  0.0321, -0.1182,  0.1145,
        -0.0688,  0.0263,  0.0026, -0.0959, -0.1220, -0.0458, -0.1112,  0.0640,
        -0.1075, -0.1043, -0.1167,  0.0753,  0.0826,  0.0483,  0.0473, -0.0785,
        -0.0483, -0.0970, -0.0397, -0.0688, -0.1157, -0.0293, -0.0616, -0.0442,
         0.1090,  0.0526,  0.0592, -0.0560,  0.0680,  0.0934,  0.0474,  0.0153,
        -0.0449, -0.0928, -0.0899,  0.0269, -0.0459,  0.0215, -0.0288,  0.0178],
       requires_grad=True), Parameter containing:
tensor([[ 0.1178, -0.0974, -0.0418,  ...,  0.1506,  0.0411, -0.1337],
        [ 0.1565, -0.0630,  0.1820,  ...,  0.2869,  0.2699,  0.2654],
        [ 0.0114,  0.1034,  0.0941,  ...,  0.0405,  0.1072, -0.2320],
        ...,
        [ 0.1984, -0.1312,  0.0974,  ...,  0.0439,  0.1998, -0.0644],
        [-0.1087, -0.0079,  0.1910,  ..., -0.2090, -0.0961,  0.1409],
        [-0.1836,  0.2026, -0.1140,  ..., -0.0153,  0.0779, -0.0386]],
       requires_grad=True), Parameter containing:
tensor([-0.0997, -0.1149, -0.0257, -0.0250,  0.0456,  0.0609,  0.0111, -0.0485,
         0.0685, -0.0240, -0.0703,  0.1091,  0.0722, -0.1171,  0.0267,  0.1032,
        -0.0184,  0.0425, -0.0475, -0.0247,  0.0577, -0.0344,  0.1164, -0.0848,
         0.0607, -0.0617, -0.0587,  0.0895, -0.0062,  0.0061, -0.1043, -0.1096,
         0.1104,  0.0225, -0.1202,  0.1193, -0.0771,  0.0698, -0.0938,  0.0639,
        -0.1088,  0.0966, -0.0665, -0.0863,  0.0912,  0.0537,  0.0411, -0.1159,
        -0.0970, -0.1208, -0.0387,  0.0274, -0.1019, -0.0128, -0.0544, -0.1024,
        -0.0281, -0.0661, -0.1196,  0.0132, -0.0459, -0.0429, -0.0592, -0.0029],
       requires_grad=True), Parameter containing:
tensor([[-0.1313,  0.1611,  0.2957,  0.1891,  0.1249,  0.1013,  0.1684,  0.3334,
         -0.4433, -0.0285, -0.0218,  0.0793,  0.1057,  0.1527,  0.0020,  0.1537,
          0.0670,  0.0077,  0.1035, -0.1063, -0.2490, -0.2002, -0.2065,  0.0257,
         -0.2566,  0.0238,  0.1859, -0.0198, -0.2353,  0.0407, -0.3542, -0.1191,
         -0.2385,  0.1859,  0.0591,  0.1548, -0.0125, -0.0107,  0.1284,  0.2131,
         -0.1626, -0.3024,  0.1589,  0.1854,  0.2244,  0.0649, -0.0410,  0.2107,
         -0.0163, -0.1029,  0.0452,  0.2244, -0.0961, -0.2350,  0.3812, -0.0138,
          0.2476, -0.3121,  0.0281,  0.0990, -0.3670, -0.1365, -0.0599,  0.1271]],
       requires_grad=True), Parameter containing:
tensor([0.0100], requires_grad=True)], 'lr': 0.01, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': False, 'initial_lr': 0.01}][W C:\cb\pytorch_1000000000000\work\torch\csrc\profiler\kineto_shim.cpp:330] Profiler is not initialized: skipping step() invocation
STAGE:2022-11-07 16:29:08 19592:4164 C:\cb\pytorch_1000000000000\work\third_party\kineto\libkineto\src\ActivityProfilerController.cpp:294] Completed Stage: Warm Up
[W C:\cb\pytorch_1000000000000\work\c10\core\CPUAllocator.cpp:231] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event
STAGE:2022-11-07 16:29:10 19592:4164 C:\cb\pytorch_1000000000000\work\third_party\kineto\libkineto\src\ActivityProfilerController.cpp:300] Completed Stage: Collection
STAGE:2022-11-07 16:29:10 19592:4164 C:\cb\pytorch_1000000000000\work\third_party\kineto\libkineto\src\output_json.cpp:417] Completed Stage: Post Processing

Iteration 0/10000, Fitting loss:  0.21076 
Iteration 10/10000, Fitting loss:  0.12104 
Traceback (most recent call last):
  File "D:\GitHub\DistributedINR\Code\train.py", line 229, in <module>
    train(model, dataset, opt)
  File "D:\GitHub\DistributedINR\Code\train.py", line 118, in train
    logging(writer, iteration, {"Fitting loss": loss}, opt, dataset.data.shape[2:], dataset)
  File "D:\GitHub\DistributedINR\Code\train.py", line 60, in logging
    log_to_writer(iteration, losses, writer, opt)
  File "D:\GitHub\DistributedINR\Code\train.py", line 34, in log_to_writer
    GBytes = (torch.cuda.max_memory_allocated(device=opt['device']) \
  File "C:\Users\Sky\anaconda3\envs\DistINR\lib\site-packages\torch\cuda\memory.py", line 352, in max_memory_allocated
    return memory_stats(device=device).get("allocated_bytes.all.peak", 0)
  File "C:\Users\Sky\anaconda3\envs\DistINR\lib\site-packages\torch\cuda\memory.py", line 209, in memory_stats
    stats = memory_stats_as_nested_dict(device=device)
  File "C:\Users\Sky\anaconda3\envs\DistINR\lib\site-packages\torch\cuda\memory.py", line 220, in memory_stats_as_nested_dict
    device = _get_device_index(device, optional=True)
  File "C:\Users\Sky\anaconda3\envs\DistINR\lib\site-packages\torch\cuda\_utils.py", line 30, in _get_device_index
    raise ValueError('Expected a cuda device, but got: {}'.format(device))
ValueError: Expected a cuda device, but got: cpu
[W C:\cb\pytorch_1000000000000\work\torch\csrc\profiler\kineto_shim.cpp:330] Profiler is not initialized: skipping step() invocation
STAGE:2022-11-07 16:30:55 19076:2776 C:\cb\pytorch_1000000000000\work\third_party\kineto\libkineto\src\ActivityProfilerController.cpp:294] Completed Stage: Warm Up
[W C:\cb\pytorch_1000000000000\work\c10\core\CPUAllocator.cpp:231] Memory block of unknown size was allocated before the profiling started, profiler results will not include the deallocation event
STAGE:2022-11-07 16:30:56 19076:2776 C:\cb\pytorch_1000000000000\work\third_party\kineto\libkineto\src\ActivityProfilerController.cpp:300] Completed Stage: Collection
STAGE:2022-11-07 16:30:56 19076:2776 C:\cb\pytorch_1000000000000\work\third_party\kineto\libkineto\src\output_json.cpp:417] Completed Stage: Post Processing
Initializing dataset - reading D:\GitHub\DistributedINR\Code\Datasets\..\..\Data\Supernova.nc
Feature grid shape: [1, 16, 64, 64, 64]
Training on cpu D:\GitHub\DistributedINR\Code\..\SavedModels\Supernova_Ryzen9_3900X_12core
Iteration 0/10000, Fitting loss:  0.21076 
Iteration 10/10000, Fitting loss:  0.12104 
Iteration 20/10000, Fitting loss:  0.06722 
Iteration 30/10000, Fitting loss:  0.03738 
Iteration 40/10000, Fitting loss:  0.03252 
Iteration 50/10000, Fitting loss:  0.01799 
Iteration 60/10000, Fitting loss:  0.01832 
Iteration 70/10000, Fitting loss:  0.01392 
Iteration 80/10000, Fitting loss:  0.01339 
Iteration 90/10000, Fitting loss:  0.01298 
Iteration 100/10000, Fitting loss:  0.00865 
Iteration 110/10000, Fitting loss:  0.01090 
Iteration 120/10000, Fitting loss:  0.00843 
Iteration 130/10000, Fitting loss:  0.01023 
Iteration 140/10000, Fitting loss:  0.00702 
Iteration 150/10000, Fitting loss:  0.00959 
Iteration 160/10000, Fitting loss:  0.00742 
Iteration 170/10000, Fitting loss:  0.00864 
Iteration 180/10000, Fitting loss:  0.00690 
Iteration 190/10000, Fitting loss:  0.00790 
Iteration 200/10000, Fitting loss:  0.00616 
Iteration 210/10000, Fitting loss:  0.00799 
Iteration 220/10000, Fitting loss:  0.00586 
Iteration 230/10000, Fitting loss:  0.00895 
Iteration 240/10000, Fitting loss:  0.00596 
Iteration 250/10000, Fitting loss:  0.00798 
Iteration 260/10000, Fitting loss:  0.00543 
Iteration 270/10000, Fitting loss:  0.00731 
Iteration 280/10000, Fitting loss:  0.00560 
Iteration 290/10000, Fitting loss:  0.00741 
Iteration 300/10000, Fitting loss:  0.00532 
Iteration 310/10000, Fitting loss:  0.00602 
Iteration 320/10000, Fitting loss:  0.00617 
Iteration 330/10000, Fitting loss:  0.00703 
Iteration 340/10000, Fitting loss:  0.00612 
Iteration 350/10000, Fitting loss:  0.00656 
Iteration 360/10000, Fitting loss:  0.00542 
Iteration 370/10000, Fitting loss:  0.00651 
Iteration 380/10000, Fitting loss:  0.00486 
Iteration 390/10000, Fitting loss:  0.00629 
Iteration 400/10000, Fitting loss:  0.00531 
Iteration 410/10000, Fitting loss:  0.00563 
Iteration 420/10000, Fitting loss:  0.00488 
Iteration 430/10000, Fitting loss:  0.00655 
Iteration 440/10000, Fitting loss:  0.00497 
Iteration 450/10000, Fitting loss:  0.00653 
Iteration 460/10000, Fitting loss:  0.00454 
Iteration 470/10000, Fitting loss:  0.00579 
Iteration 480/10000, Fitting loss:  0.00513 
Iteration 490/10000, Fitting loss:  0.00596 
Iteration 500/10000, Fitting loss:  0.00510 
Iteration 510/10000, Fitting loss:  0.00637 
Iteration 520/10000, Fitting loss:  0.00414 
Iteration 530/10000, Fitting loss:  0.00638 
Iteration 540/10000, Fitting loss:  0.00421 
Iteration 550/10000, Fitting loss:  0.00633 
Iteration 560/10000, Fitting loss:  0.00438 
Iteration 570/10000, Fitting loss:  0.00591 
Iteration 580/10000, Fitting loss:  0.00422 
Iteration 590/10000, Fitting loss:  0.00568 
Iteration 600/10000, Fitting loss:  0.00468 
Iteration 610/10000, Fitting loss:  0.00571 
Iteration 620/10000, Fitting loss:  0.00415 
Iteration 630/10000, Fitting loss:  0.00570 
Iteration 640/10000, Fitting loss:  0.00445 
Iteration 650/10000, Fitting loss:  0.00570 
Iteration 660/10000, Fitting loss:  0.00424 
Iteration 670/10000, Fitting loss:  0.00547 
Iteration 680/10000, Fitting loss:  0.00430 
Iteration 690/10000, Fitting loss:  0.00535 
Iteration 700/10000, Fitting loss:  0.00396 
Iteration 710/10000, Fitting loss:  0.00543 
Iteration 720/10000, Fitting loss:  0.00554 
Iteration 730/10000, Fitting loss:  0.00611 
Iteration 740/10000, Fitting loss:  0.00485 
Iteration 750/10000, Fitting loss:  0.00507 
Iteration 760/10000, Fitting loss:  0.00449 
Iteration 770/10000, Fitting loss:  0.00523 
Iteration 780/10000, Fitting loss:  0.00401 
Iteration 790/10000, Fitting loss:  0.00508 
Iteration 800/10000, Fitting loss:  0.00373 
Iteration 810/10000, Fitting loss:  0.00515 
Iteration 820/10000, Fitting loss:  0.00463 
Iteration 830/10000, Fitting loss:  0.00500 
Iteration 840/10000, Fitting loss:  0.00398 
Iteration 850/10000, Fitting loss:  0.00517 
Iteration 860/10000, Fitting loss:  0.00447 
Iteration 870/10000, Fitting loss:  0.00517 
Iteration 880/10000, Fitting loss:  0.00427 
Iteration 890/10000, Fitting loss:  0.00517 
Iteration 900/10000, Fitting loss:  0.00390 
Iteration 910/10000, Fitting loss:  0.00475 
Iteration 920/10000, Fitting loss:  0.00378 
Iteration 930/10000, Fitting loss:  0.00492 
Iteration 940/10000, Fitting loss:  0.00372 
Iteration 950/10000, Fitting loss:  0.00504 
Iteration 960/10000, Fitting loss:  0.00400 
Iteration 970/10000, Fitting loss:  0.00476 
Iteration 980/10000, Fitting loss:  0.00435 
Iteration 990/10000, Fitting loss:  0.00517 
Iteration 1000/10000, Fitting loss:  0.00404 
Iteration 1010/10000, Fitting loss:  0.00385 
Iteration 1020/10000, Fitting loss:  0.00478 
Iteration 1030/10000, Fitting loss:  0.00458 
Iteration 1040/10000, Fitting loss:  0.00344 
Iteration 1050/10000, Fitting loss:  0.00489 
Iteration 1060/10000, Fitting loss:  0.00376 
Iteration 1070/10000, Fitting loss:  0.00474 
Iteration 1080/10000, Fitting loss:  0.00355 
Iteration 1090/10000, Fitting loss:  0.00467 
Iteration 1100/10000, Fitting loss:  0.00444 
Iteration 1110/10000, Fitting loss:  0.00471 
Iteration 1120/10000, Fitting loss:  0.00352 
Iteration 1130/10000, Fitting loss:  0.00456 
Iteration 1140/10000, Fitting loss:  0.00395 
Iteration 1150/10000, Fitting loss:  0.00489 
Iteration 1160/10000, Fitting loss:  0.00364 
Iteration 1170/10000, Fitting loss:  0.00458 
Iteration 1180/10000, Fitting loss:  0.00363 
Iteration 1190/10000, Fitting loss:  0.00466 
Iteration 1200/10000, Fitting loss:  0.00365 
Iteration 1210/10000, Fitting loss:  0.00430 
Iteration 1220/10000, Fitting loss:  0.00361 
Iteration 1230/10000, Fitting loss:  0.00453 
Iteration 1240/10000, Fitting loss:  0.00391 
Iteration 1250/10000, Fitting loss:  0.00451 
Iteration 1260/10000, Fitting loss:  0.00372 
Iteration 1270/10000, Fitting loss:  0.00434 
Iteration 1280/10000, Fitting loss:  0.00345 
Iteration 1290/10000, Fitting loss:  0.00455 
Iteration 1300/10000, Fitting loss:  0.00359 
Iteration 1310/10000, Fitting loss:  0.00449 
Iteration 1320/10000, Fitting loss:  0.00341 
Iteration 1330/10000, Fitting loss:  0.00405 
Iteration 1340/10000, Fitting loss:  0.00391 
Iteration 1350/10000, Fitting loss:  0.00449 
Iteration 1360/10000, Fitting loss:  0.00318 
Iteration 1370/10000, Fitting loss:  0.00412 
Iteration 1380/10000, Fitting loss:  0.00364 
Iteration 1390/10000, Fitting loss:  0.00422 
Iteration 1400/10000, Fitting loss:  0.00318 
Iteration 1410/10000, Fitting loss:  0.00422 
Iteration 1420/10000, Fitting loss:  0.00346 
Iteration 1430/10000, Fitting loss:  0.00427 
Iteration 1440/10000, Fitting loss:  0.00352 
Iteration 1450/10000, Fitting loss:  0.00441 
Iteration 1460/10000, Fitting loss:  0.00357 
Iteration 1470/10000, Fitting loss:  0.00428 
Iteration 1480/10000, Fitting loss:  0.00351 
Iteration 1490/10000, Fitting loss:  0.00424 
Iteration 1500/10000, Fitting loss:  0.00360 
Iteration 1510/10000, Fitting loss:  0.00435 
Iteration 1520/10000, Fitting loss:  0.00342 
Iteration 1530/10000, Fitting loss:  0.00393 
Iteration 1540/10000, Fitting loss:  0.00345 
Iteration 1550/10000, Fitting loss:  0.00419 
Iteration 1560/10000, Fitting loss:  0.00325 
Iteration 1570/10000, Fitting loss:  0.00393 
Iteration 1580/10000, Fitting loss:  0.00321 
Iteration 1590/10000, Fitting loss:  0.00423 
Iteration 1600/10000, Fitting loss:  0.00301 
Iteration 1610/10000, Fitting loss:  0.00407 
Iteration 1620/10000, Fitting loss:  0.00341 
Iteration 1630/10000, Fitting loss:  0.00397 
Iteration 1640/10000, Fitting loss:  0.00335 
Iteration 1650/10000, Fitting loss:  0.00400 
Iteration 1660/10000, Fitting loss:  0.00320 
Iteration 1670/10000, Fitting loss:  0.00390 
Iteration 1680/10000, Fitting loss:  0.00318 
Iteration 1690/10000, Fitting loss:  0.00386 
Iteration 1700/10000, Fitting loss:  0.00316 
Iteration 1710/10000, Fitting loss:  0.00423 
Iteration 1720/10000, Fitting loss:  0.00329 
Iteration 1730/10000, Fitting loss:  0.00413 
Iteration 1740/10000, Fitting loss:  0.00321 
Iteration 1750/10000, Fitting loss:  0.00389 
Iteration 1760/10000, Fitting loss:  0.00325 
Iteration 1770/10000, Fitting loss:  0.00337 
Iteration 1780/10000, Fitting loss:  0.00390 
Iteration 1790/10000, Fitting loss:  0.00361 
Iteration 1800/10000, Fitting loss:  0.00345 
Iteration 1810/10000, Fitting loss:  0.00415 
Iteration 1820/10000, Fitting loss:  0.00361 
Iteration 1830/10000, Fitting loss:  0.00327 
Iteration 1840/10000, Fitting loss:  0.00376 
Iteration 1850/10000, Fitting loss:  0.00335 
Iteration 1860/10000, Fitting loss:  0.00353 
Iteration 1870/10000, Fitting loss:  0.00402 
Iteration 1880/10000, Fitting loss:  0.00318 
Iteration 1890/10000, Fitting loss:  0.00386 
Iteration 1900/10000, Fitting loss:  0.00349 
Iteration 1910/10000, Fitting loss:  0.00364 
Iteration 1920/10000, Fitting loss:  0.00331 
Iteration 1930/10000, Fitting loss:  0.00352 
Iteration 1940/10000, Fitting loss:  0.00328 
Iteration 1950/10000, Fitting loss:  0.00374 
Iteration 1960/10000, Fitting loss:  0.00313 
Iteration 1970/10000, Fitting loss:  0.00373 
Iteration 1980/10000, Fitting loss:  0.00332 
Iteration 1990/10000, Fitting loss:  0.00379 
Iteration 2000/10000, Fitting loss:  0.00364 
Iteration 2010/10000, Fitting loss:  0.00369 
Iteration 2020/10000, Fitting loss:  0.00318 
Iteration 2030/10000, Fitting loss:  0.00389 
Iteration 2040/10000, Fitting loss:  0.00297 
Iteration 2050/10000, Fitting loss:  0.00356 
Iteration 2060/10000, Fitting loss:  0.00303 
Iteration 2070/10000, Fitting loss:  0.00359 
Iteration 2080/10000, Fitting loss:  0.00334 
Iteration 2090/10000, Fitting loss:  0.00355 
Iteration 2100/10000, Fitting loss:  0.00330 
Iteration 2110/10000, Fitting loss:  0.00362 
Iteration 2120/10000, Fitting loss:  0.00334 
Iteration 2130/10000, Fitting loss:  0.00339 
Iteration 2140/10000, Fitting loss:  0.00340 
Iteration 2150/10000, Fitting loss:  0.00361 
Iteration 2160/10000, Fitting loss:  0.00338 
Iteration 2170/10000, Fitting loss:  0.00358 
Iteration 2180/10000, Fitting loss:  0.00334 
Iteration 2190/10000, Fitting loss:  0.00360 
Iteration 2200/10000, Fitting loss:  0.00324 
Iteration 2210/10000, Fitting loss:  0.00353 
Iteration 2220/10000, Fitting loss:  0.00287 
Iteration 2230/10000, Fitting loss:  0.00364 
Iteration 2240/10000, Fitting loss:  0.00315 
Iteration 2250/10000, Fitting loss:  0.00359 
Iteration 2260/10000, Fitting loss:  0.00262 
Iteration 2270/10000, Fitting loss:  0.00368 
Iteration 2280/10000, Fitting loss:  0.00293 
Iteration 2290/10000, Fitting loss:  0.00341 
Iteration 2300/10000, Fitting loss:  0.00304 
Iteration 2310/10000, Fitting loss:  0.00341 
Iteration 2320/10000, Fitting loss:  0.00295 
Iteration 2330/10000, Fitting loss:  0.00339 
Iteration 2340/10000, Fitting loss:  0.00324 
Iteration 2350/10000, Fitting loss:  0.00340 
Iteration 2360/10000, Fitting loss:  0.00299 
Iteration 2370/10000, Fitting loss:  0.00366 
Iteration 2380/10000, Fitting loss:  0.00311 
Iteration 2390/10000, Fitting loss:  0.00311 
Iteration 2400/10000, Fitting loss:  0.00294 
Iteration 2410/10000, Fitting loss:  0.00341 
Iteration 2420/10000, Fitting loss:  0.00274 
Iteration 2430/10000, Fitting loss:  0.00337 
Iteration 2440/10000, Fitting loss:  0.00316 
Iteration 2450/10000, Fitting loss:  0.00351 
Iteration 2460/10000, Fitting loss:  0.00296 
Iteration 2470/10000, Fitting loss:  0.00332 
Iteration 2480/10000, Fitting loss:  0.00324 
Iteration 2490/10000, Fitting loss:  0.00337 
Iteration 2500/10000, Fitting loss:  0.00306 
Iteration 2510/10000, Fitting loss:  0.00327 
Iteration 2520/10000, Fitting loss:  0.00361 
Iteration 2530/10000, Fitting loss:  0.00345 
Iteration 2540/10000, Fitting loss:  0.00308 
Iteration 2550/10000, Fitting loss:  0.00362 
Iteration 2560/10000, Fitting loss:  0.00331 
Iteration 2570/10000, Fitting loss:  0.00312 
Iteration 2580/10000, Fitting loss:  0.00338 
Iteration 2590/10000, Fitting loss:  0.00344 
Iteration 2600/10000, Fitting loss:  0.00297 
Iteration 2610/10000, Fitting loss:  0.00352 
Iteration 2620/10000, Fitting loss:  0.00307 
Iteration 2630/10000, Fitting loss:  0.00326 
Iteration 2640/10000, Fitting loss:  0.00343 
Iteration 2650/10000, Fitting loss:  0.00312 
Iteration 2660/10000, Fitting loss:  0.00313 
Iteration 2670/10000, Fitting loss:  0.00354 
Iteration 2680/10000, Fitting loss:  0.00275 
Iteration 2690/10000, Fitting loss:  0.00339 
Iteration 2700/10000, Fitting loss:  0.00322 
Iteration 2710/10000, Fitting loss:  0.00316 
Iteration 2720/10000, Fitting loss:  0.00324 
Iteration 2730/10000, Fitting loss:  0.00351 
Iteration 2740/10000, Fitting loss:  0.00304 
Iteration 2750/10000, Fitting loss:  0.00380 
Iteration 2760/10000, Fitting loss:  0.00333 
Iteration 2770/10000, Fitting loss:  0.00316 
Iteration 2780/10000, Fitting loss:  0.00365 
Iteration 2790/10000, Fitting loss:  0.00310 
Iteration 2800/10000, Fitting loss:  0.00329 
Iteration 2810/10000, Fitting loss:  0.00324 
Iteration 2820/10000, Fitting loss:  0.00279 
Iteration 2830/10000, Fitting loss:  0.00352 
Iteration 2840/10000, Fitting loss:  0.00289 
Iteration 2850/10000, Fitting loss:  0.00346 
Iteration 2860/10000, Fitting loss:  0.00312 
Iteration 2870/10000, Fitting loss:  0.00323 
Iteration 2880/10000, Fitting loss:  0.00296 
Iteration 2890/10000, Fitting loss:  0.00356 
Iteration 2900/10000, Fitting loss:  0.00286 
Iteration 2910/10000, Fitting loss:  0.00352 
Iteration 2920/10000, Fitting loss:  0.00299 
Iteration 2930/10000, Fitting loss:  0.00320 
Iteration 2940/10000, Fitting loss:  0.00285 
Iteration 2950/10000, Fitting loss:  0.00352 
Iteration 2960/10000, Fitting loss:  0.00326 
Iteration 2970/10000, Fitting loss:  0.00268 
Iteration 2980/10000, Fitting loss:  0.00379 
Iteration 2990/10000, Fitting loss:  0.00763 
Iteration 3000/10000, Fitting loss:  0.00576 
Iteration 3010/10000, Fitting loss:  0.00341 
Iteration 3020/10000, Fitting loss:  0.00365 
Iteration 3030/10000, Fitting loss:  0.00365 
Iteration 3040/10000, Fitting loss:  0.00311 
Iteration 3050/10000, Fitting loss:  0.00323 
Iteration 3060/10000, Fitting loss:  0.00335 
Iteration 3070/10000, Fitting loss:  0.00305 
Iteration 3080/10000, Fitting loss:  0.00343 
Iteration 3090/10000, Fitting loss:  0.00289 
Iteration 3100/10000, Fitting loss:  0.00334 
Iteration 3110/10000, Fitting loss:  0.00278 
Iteration 3120/10000, Fitting loss:  0.00293 
Iteration 3130/10000, Fitting loss:  0.00296 
Iteration 3140/10000, Fitting loss:  0.00309 
Iteration 3150/10000, Fitting loss:  0.00341 
Iteration 3160/10000, Fitting loss:  0.00279 
Iteration 3170/10000, Fitting loss:  0.00322 
Iteration 3180/10000, Fitting loss:  0.00329 
Iteration 3190/10000, Fitting loss:  0.00292 
Iteration 3200/10000, Fitting loss:  0.00322 
Iteration 3210/10000, Fitting loss:  0.00307 
Iteration 3220/10000, Fitting loss:  0.00294 
Iteration 3230/10000, Fitting loss:  0.00316 
Iteration 3240/10000, Fitting loss:  0.00299 
Iteration 3250/10000, Fitting loss:  0.00336 
Iteration 3260/10000, Fitting loss:  0.00292 
Iteration 3270/10000, Fitting loss:  0.00307 
Iteration 3280/10000, Fitting loss:  0.00317 
Iteration 3290/10000, Fitting loss:  0.00298 
Iteration 3300/10000, Fitting loss:  0.00338 
Iteration 3310/10000, Fitting loss:  0.00271 
Iteration 3320/10000, Fitting loss:  0.00345 
Iteration 3330/10000, Fitting loss:  0.00311 
Iteration 3340/10000, Fitting loss:  0.00265 
Iteration 3350/10000, Fitting loss:  0.00224 
Iteration 3360/10000, Fitting loss:  0.00232 
Iteration 3370/10000, Fitting loss:  0.00225 
Iteration 3380/10000, Fitting loss:  0.00227 
Iteration 3390/10000, Fitting loss:  0.00218 
Iteration 3400/10000, Fitting loss:  0.00223 
Iteration 3410/10000, Fitting loss:  0.00221 
Iteration 3420/10000, Fitting loss:  0.00224 
Iteration 3430/10000, Fitting loss:  0.00222 
Iteration 3440/10000, Fitting loss:  0.00212 
Iteration 3450/10000, Fitting loss:  0.00215 
Iteration 3460/10000, Fitting loss:  0.00203 
Iteration 3470/10000, Fitting loss:  0.00209 
Iteration 3480/10000, Fitting loss:  0.00223 
Iteration 3490/10000, Fitting loss:  0.00232 
Iteration 3500/10000, Fitting loss:  0.00203 
Iteration 3510/10000, Fitting loss:  0.00216 
Iteration 3520/10000, Fitting loss:  0.00203 
Iteration 3530/10000, Fitting loss:  0.00220 
Iteration 3540/10000, Fitting loss:  0.00205 
Iteration 3550/10000, Fitting loss:  0.00206 
Iteration 3560/10000, Fitting loss:  0.00203 
Iteration 3570/10000, Fitting loss:  0.00208 
Iteration 3580/10000, Fitting loss:  0.00210 
Iteration 3590/10000, Fitting loss:  0.00210 
Iteration 3600/10000, Fitting loss:  0.00197 
Iteration 3610/10000, Fitting loss:  0.00197 
Iteration 3620/10000, Fitting loss:  0.00202 
Iteration 3630/10000, Fitting loss:  0.00202 
Iteration 3640/10000, Fitting loss:  0.00210 
Iteration 3650/10000, Fitting loss:  0.00205 
Iteration 3660/10000, Fitting loss:  0.00197 
Iteration 3670/10000, Fitting loss:  0.00203 
Iteration 3680/10000, Fitting loss:  0.00203 
Iteration 3690/10000, Fitting loss:  0.00188 
Iteration 3700/10000, Fitting loss:  0.00199 
Iteration 3710/10000, Fitting loss:  0.00211 
Iteration 3720/10000, Fitting loss:  0.00193 
Iteration 3730/10000, Fitting loss:  0.00191 
Iteration 3740/10000, Fitting loss:  0.00218 
Iteration 3750/10000, Fitting loss:  0.00207 
Iteration 3760/10000, Fitting loss:  0.00198 
Iteration 3770/10000, Fitting loss:  0.00194 
Iteration 3780/10000, Fitting loss:  0.00196 
Iteration 3790/10000, Fitting loss:  0.00216 
Iteration 3800/10000, Fitting loss:  0.00192 
Iteration 3810/10000, Fitting loss:  0.00197 
Iteration 3820/10000, Fitting loss:  0.00216 
Iteration 3830/10000, Fitting loss:  0.00200 
Iteration 3840/10000, Fitting loss:  0.00190 
Iteration 3850/10000, Fitting loss:  0.00201 
Iteration 3860/10000, Fitting loss:  0.00198 
Iteration 3870/10000, Fitting loss:  0.00184 
Iteration 3880/10000, Fitting loss:  0.00206 
Iteration 3890/10000, Fitting loss:  0.00194 
Iteration 3900/10000, Fitting loss:  0.00196 
Iteration 3910/10000, Fitting loss:  0.00204 
Iteration 3920/10000, Fitting loss:  0.00191 
Iteration 3930/10000, Fitting loss:  0.00200 
Iteration 3940/10000, Fitting loss:  0.00197 
Iteration 3950/10000, Fitting loss:  0.00214 
Iteration 3960/10000, Fitting loss:  0.00200 
Iteration 3970/10000, Fitting loss:  0.00191 
Iteration 3980/10000, Fitting loss:  0.00205 
Iteration 3990/10000, Fitting loss:  0.00205 
Iteration 4000/10000, Fitting loss:  0.00198 
Iteration 4010/10000, Fitting loss:  0.00192 
Iteration 4020/10000, Fitting loss:  0.00191 
Iteration 4030/10000, Fitting loss:  0.00190 
Iteration 4040/10000, Fitting loss:  0.00190 
Iteration 4050/10000, Fitting loss:  0.00191 
Iteration 4060/10000, Fitting loss:  0.00195 
Iteration 4070/10000, Fitting loss:  0.00194 
Iteration 4080/10000, Fitting loss:  0.00187 
Iteration 4090/10000, Fitting loss:  0.00189 
Iteration 4100/10000, Fitting loss:  0.00183 
Iteration 4110/10000, Fitting loss:  0.00197 
Iteration 4120/10000, Fitting loss:  0.00186 
Iteration 4130/10000, Fitting loss:  0.00194 
Iteration 4140/10000, Fitting loss:  0.00188 
Iteration 4150/10000, Fitting loss:  0.00193 
Iteration 4160/10000, Fitting loss:  0.00191 
Iteration 4170/10000, Fitting loss:  0.00186 
Iteration 4180/10000, Fitting loss:  0.00184 
Iteration 4190/10000, Fitting loss:  0.00188 
Iteration 4200/10000, Fitting loss:  0.00193 
Iteration 4210/10000, Fitting loss:  0.00179 
Iteration 4220/10000, Fitting loss:  0.00198 
Iteration 4230/10000, Fitting loss:  0.00175 
Iteration 4240/10000, Fitting loss:  0.00192 
Iteration 4250/10000, Fitting loss:  0.00182 
Iteration 4260/10000, Fitting loss:  0.00187 
Iteration 4270/10000, Fitting loss:  0.00192 
Iteration 4280/10000, Fitting loss:  0.00201 
Iteration 4290/10000, Fitting loss:  0.00183 
Iteration 4300/10000, Fitting loss:  0.00191 
Iteration 4310/10000, Fitting loss:  0.00193 
Iteration 4320/10000, Fitting loss:  0.00185 
Iteration 4330/10000, Fitting loss:  0.00190 
Iteration 4340/10000, Fitting loss:  0.00193 
Iteration 4350/10000, Fitting loss:  0.00194 
Iteration 4360/10000, Fitting loss:  0.00194 
Iteration 4370/10000, Fitting loss:  0.00198 
Iteration 4380/10000, Fitting loss:  0.00196 
Iteration 4390/10000, Fitting loss:  0.00186 
Iteration 4400/10000, Fitting loss:  0.00189 
Iteration 4410/10000, Fitting loss:  0.00186 
Iteration 4420/10000, Fitting loss:  0.00192 
Iteration 4430/10000, Fitting loss:  0.00189 
Iteration 4440/10000, Fitting loss:  0.00186 
Iteration 4450/10000, Fitting loss:  0.00186 
Iteration 4460/10000, Fitting loss:  0.00188 
Iteration 4470/10000, Fitting loss:  0.00180 
Iteration 4480/10000, Fitting loss:  0.00190 
Iteration 4490/10000, Fitting loss:  0.00187 
Iteration 4500/10000, Fitting loss:  0.00175 
Iteration 4510/10000, Fitting loss:  0.00185 
Iteration 4520/10000, Fitting loss:  0.00187 
Iteration 4530/10000, Fitting loss:  0.00187 
Iteration 4540/10000, Fitting loss:  0.00190 
Iteration 4550/10000, Fitting loss:  0.00185 
Iteration 4560/10000, Fitting loss:  0.00189 
Iteration 4570/10000, Fitting loss:  0.00186 
Iteration 4580/10000, Fitting loss:  0.00186 
Iteration 4590/10000, Fitting loss:  0.00181 
Iteration 4600/10000, Fitting loss:  0.00187 
Iteration 4610/10000, Fitting loss:  0.00180 
Iteration 4620/10000, Fitting loss:  0.00179 
Iteration 4630/10000, Fitting loss:  0.00193 
Iteration 4640/10000, Fitting loss:  0.00180 
Iteration 4650/10000, Fitting loss:  0.00186 
Iteration 4660/10000, Fitting loss:  0.00187 
Iteration 4670/10000, Fitting loss:  0.00182 
Iteration 4680/10000, Fitting loss:  0.00203 
Iteration 4690/10000, Fitting loss:  0.00185 
Iteration 4700/10000, Fitting loss:  0.00194 
Iteration 4710/10000, Fitting loss:  0.00185 
Iteration 4720/10000, Fitting loss:  0.00185 
Iteration 4730/10000, Fitting loss:  0.00179 
Iteration 4740/10000, Fitting loss:  0.00178 
Iteration 4750/10000, Fitting loss:  0.00190 
Iteration 4760/10000, Fitting loss:  0.00189 
Iteration 4770/10000, Fitting loss:  0.00181 
Iteration 4780/10000, Fitting loss:  0.00184 
Iteration 4790/10000, Fitting loss:  0.00173 
Iteration 4800/10000, Fitting loss:  0.00190 
Iteration 4810/10000, Fitting loss:  0.00183 
Iteration 4820/10000, Fitting loss:  0.00185 
Iteration 4830/10000, Fitting loss:  0.00182 
Iteration 4840/10000, Fitting loss:  0.00187 
Iteration 4850/10000, Fitting loss:  0.00189 
Iteration 4860/10000, Fitting loss:  0.00186 
Iteration 4870/10000, Fitting loss:  0.00182 
Iteration 4880/10000, Fitting loss:  0.00183 
Iteration 4890/10000, Fitting loss:  0.00185 
Iteration 4900/10000, Fitting loss:  0.00175 
Iteration 4910/10000, Fitting loss:  0.00178 
Iteration 4920/10000, Fitting loss:  0.00187 
Iteration 4930/10000, Fitting loss:  0.00178 
Iteration 4940/10000, Fitting loss:  0.00197 
Iteration 4950/10000, Fitting loss:  0.00176 
Iteration 4960/10000, Fitting loss:  0.00182 
Iteration 4970/10000, Fitting loss:  0.00181 
Iteration 4980/10000, Fitting loss:  0.00198 
Iteration 4990/10000, Fitting loss:  0.00199 
Iteration 5000/10000, Fitting loss:  0.00179 
Iteration 5010/10000, Fitting loss:  0.00177 
Iteration 5020/10000, Fitting loss:  0.00186 
Iteration 5030/10000, Fitting loss:  0.00187 
Iteration 5040/10000, Fitting loss:  0.00187 
Iteration 5050/10000, Fitting loss:  0.00191 
Iteration 5060/10000, Fitting loss:  0.00186 
Iteration 5070/10000, Fitting loss:  0.00189 
Iteration 5080/10000, Fitting loss:  0.00180 
Iteration 5090/10000, Fitting loss:  0.00175 
Iteration 5100/10000, Fitting loss:  0.00181 
Iteration 5110/10000, Fitting loss:  0.00183 
Iteration 5120/10000, Fitting loss:  0.00180 
Iteration 5130/10000, Fitting loss:  0.00182 
Iteration 5140/10000, Fitting loss:  0.00180 
Iteration 5150/10000, Fitting loss:  0.00172 
Iteration 5160/10000, Fitting loss:  0.00172 
Iteration 5170/10000, Fitting loss:  0.00178 
Iteration 5180/10000, Fitting loss:  0.00175 
Iteration 5190/10000, Fitting loss:  0.00184 
Iteration 5200/10000, Fitting loss:  0.00175 
Iteration 5210/10000, Fitting loss:  0.00195 
Iteration 5220/10000, Fitting loss:  0.00182 
Iteration 5230/10000, Fitting loss:  0.00178 
Iteration 5240/10000, Fitting loss:  0.00180 
Iteration 5250/10000, Fitting loss:  0.00194 
Iteration 5260/10000, Fitting loss:  0.00188 
Iteration 5270/10000, Fitting loss:  0.00173 
Iteration 5280/10000, Fitting loss:  0.00171 
Iteration 5290/10000, Fitting loss:  0.00177 
Iteration 5300/10000, Fitting loss:  0.00182 
Iteration 5310/10000, Fitting loss:  0.00187 
Iteration 5320/10000, Fitting loss:  0.00174 
Iteration 5330/10000, Fitting loss:  0.00178 
Iteration 5340/10000, Fitting loss:  0.00190 
Iteration 5350/10000, Fitting loss:  0.00182 
Iteration 5360/10000, Fitting loss:  0.00192 
Iteration 5370/10000, Fitting loss:  0.00187 
Iteration 5380/10000, Fitting loss:  0.00177 
Iteration 5390/10000, Fitting loss:  0.00182 
Iteration 5400/10000, Fitting loss:  0.00172 
Iteration 5410/10000, Fitting loss:  0.00183 
Iteration 5420/10000, Fitting loss:  0.00188 
Iteration 5430/10000, Fitting loss:  0.00175 
Iteration 5440/10000, Fitting loss:  0.00179 
Iteration 5450/10000, Fitting loss:  0.00175 
Iteration 5460/10000, Fitting loss:  0.00174 
Iteration 5470/10000, Fitting loss:  0.00177 
Iteration 5480/10000, Fitting loss:  0.00181 
Iteration 5490/10000, Fitting loss:  0.00174 
Iteration 5500/10000, Fitting loss:  0.00177 
Iteration 5510/10000, Fitting loss:  0.00166 
Iteration 5520/10000, Fitting loss:  0.00174 
Iteration 5530/10000, Fitting loss:  0.00182 
Iteration 5540/10000, Fitting loss:  0.00173 
Iteration 5550/10000, Fitting loss:  0.00183 
Iteration 5560/10000, Fitting loss:  0.00192 
Iteration 5570/10000, Fitting loss:  0.00181 
Iteration 5580/10000, Fitting loss:  0.00182 
Iteration 5590/10000, Fitting loss:  0.00176 
Iteration 5600/10000, Fitting loss:  0.00172 
Iteration 5610/10000, Fitting loss:  0.00188 
Iteration 5620/10000, Fitting loss:  0.00174 
Iteration 5630/10000, Fitting loss:  0.00178 
Iteration 5640/10000, Fitting loss:  0.00174 
Iteration 5650/10000, Fitting loss:  0.00173 
Iteration 5660/10000, Fitting loss:  0.00184 
Iteration 5670/10000, Fitting loss:  0.00179 
Iteration 5680/10000, Fitting loss:  0.00174 
Iteration 5690/10000, Fitting loss:  0.00179 
Iteration 5700/10000, Fitting loss:  0.00166 
Iteration 5710/10000, Fitting loss:  0.00173 
Iteration 5720/10000, Fitting loss:  0.00176 
Iteration 5730/10000, Fitting loss:  0.00166 
Iteration 5740/10000, Fitting loss:  0.00170 
Iteration 5750/10000, Fitting loss:  0.00171 
Iteration 5760/10000, Fitting loss:  0.00174 
Iteration 5770/10000, Fitting loss:  0.00174 
Iteration 5780/10000, Fitting loss:  0.00181 
Iteration 5790/10000, Fitting loss:  0.00185 
Iteration 5800/10000, Fitting loss:  0.00183 
Iteration 5810/10000, Fitting loss:  0.00189 
Iteration 5820/10000, Fitting loss:  0.00177 
Iteration 5830/10000, Fitting loss:  0.00181 
Iteration 5840/10000, Fitting loss:  0.00179 
Iteration 5850/10000, Fitting loss:  0.00163 
Iteration 5860/10000, Fitting loss:  0.00173 
Iteration 5870/10000, Fitting loss:  0.00172 
Iteration 5880/10000, Fitting loss:  0.00185 
Iteration 5890/10000, Fitting loss:  0.00182 
Iteration 5900/10000, Fitting loss:  0.00183 
Iteration 5910/10000, Fitting loss:  0.00175 
Iteration 5920/10000, Fitting loss:  0.00177 
Iteration 5930/10000, Fitting loss:  0.00183 
Iteration 5940/10000, Fitting loss:  0.00171 
Iteration 5950/10000, Fitting loss:  0.00185 
Iteration 5960/10000, Fitting loss:  0.00174 
Iteration 5970/10000, Fitting loss:  0.00191 
Iteration 5980/10000, Fitting loss:  0.00184 
Iteration 5990/10000, Fitting loss:  0.00173 
Iteration 6000/10000, Fitting loss:  0.00174 
Iteration 6010/10000, Fitting loss:  0.00174 
Iteration 6020/10000, Fitting loss:  0.00180 
Iteration 6030/10000, Fitting loss:  0.00169 
Iteration 6040/10000, Fitting loss:  0.00180 
Iteration 6050/10000, Fitting loss:  0.00175 
Iteration 6060/10000, Fitting loss:  0.00183 
Iteration 6070/10000, Fitting loss:  0.00178 
Iteration 6080/10000, Fitting loss:  0.00172 
Iteration 6090/10000, Fitting loss:  0.00179 
Iteration 6100/10000, Fitting loss:  0.00182 
Iteration 6110/10000, Fitting loss:  0.00173 
Iteration 6120/10000, Fitting loss:  0.00174 
Iteration 6130/10000, Fitting loss:  0.00189 
Iteration 6140/10000, Fitting loss:  0.00172 
Iteration 6150/10000, Fitting loss:  0.00187 
Iteration 6160/10000, Fitting loss:  0.00183 
Iteration 6170/10000, Fitting loss:  0.00186 
Iteration 6180/10000, Fitting loss:  0.00169 
Iteration 6190/10000, Fitting loss:  0.00184 
Iteration 6200/10000, Fitting loss:  0.00176 
Iteration 6210/10000, Fitting loss:  0.00164 
Iteration 6220/10000, Fitting loss:  0.00181 
Iteration 6230/10000, Fitting loss:  0.00175 
Iteration 6240/10000, Fitting loss:  0.00186 
Iteration 6250/10000, Fitting loss:  0.00183 
Iteration 6260/10000, Fitting loss:  0.00180 
Iteration 6270/10000, Fitting loss:  0.00183 
Iteration 6280/10000, Fitting loss:  0.00178 
Iteration 6290/10000, Fitting loss:  0.00175 
Iteration 6300/10000, Fitting loss:  0.00177 
Iteration 6310/10000, Fitting loss:  0.00180 
Iteration 6320/10000, Fitting loss:  0.00183 
Iteration 6330/10000, Fitting loss:  0.00172 
Iteration 6340/10000, Fitting loss:  0.00174 
Iteration 6350/10000, Fitting loss:  0.00179 
Iteration 6360/10000, Fitting loss:  0.00191 
Iteration 6370/10000, Fitting loss:  0.00178 
Iteration 6380/10000, Fitting loss:  0.00189 
Iteration 6390/10000, Fitting loss:  0.00183 
Iteration 6400/10000, Fitting loss:  0.00170 
Iteration 6410/10000, Fitting loss:  0.00183 
Iteration 6420/10000, Fitting loss:  0.00183 
Iteration 6430/10000, Fitting loss:  0.00182 
Iteration 6440/10000, Fitting loss:  0.00178 
Iteration 6450/10000, Fitting loss:  0.00179 
Iteration 6460/10000, Fitting loss:  0.00164 
Iteration 6470/10000, Fitting loss:  0.00176 
Iteration 6480/10000, Fitting loss:  0.00187 
Iteration 6490/10000, Fitting loss:  0.00172 
Iteration 6500/10000, Fitting loss:  0.00178 
Iteration 6510/10000, Fitting loss:  0.00162 
Iteration 6520/10000, Fitting loss:  0.00173 
Iteration 6530/10000, Fitting loss:  0.00174 
Iteration 6540/10000, Fitting loss:  0.00176 
Iteration 6550/10000, Fitting loss:  0.00184 
Iteration 6560/10000, Fitting loss:  0.00176 
Iteration 6570/10000, Fitting loss:  0.00171 
Iteration 6580/10000, Fitting loss:  0.00175 
Iteration 6590/10000, Fitting loss:  0.00180 
Iteration 6600/10000, Fitting loss:  0.00168 
Iteration 6610/10000, Fitting loss:  0.00174 
Iteration 6620/10000, Fitting loss:  0.00184 
Iteration 6630/10000, Fitting loss:  0.00178 
Iteration 6640/10000, Fitting loss:  0.00175 
Iteration 6650/10000, Fitting loss:  0.00179 
Iteration 6660/10000, Fitting loss:  0.00182 
Iteration 6670/10000, Fitting loss:  0.00172 
Iteration 6680/10000, Fitting loss:  0.00171 
Iteration 6690/10000, Fitting loss:  0.00159 
Iteration 6700/10000, Fitting loss:  0.00168 
Iteration 6710/10000, Fitting loss:  0.00167 
Iteration 6720/10000, Fitting loss:  0.00170 
Iteration 6730/10000, Fitting loss:  0.00170 
Iteration 6740/10000, Fitting loss:  0.00161 
Iteration 6750/10000, Fitting loss:  0.00161 
Iteration 6760/10000, Fitting loss:  0.00167 
Iteration 6770/10000, Fitting loss:  0.00163 
Iteration 6780/10000, Fitting loss:  0.00161 
Iteration 6790/10000, Fitting loss:  0.00160 
Iteration 6800/10000, Fitting loss:  0.00161 
Iteration 6810/10000, Fitting loss:  0.00160 
Iteration 6820/10000, Fitting loss:  0.00162 
Iteration 6830/10000, Fitting loss:  0.00174 
Iteration 6840/10000, Fitting loss:  0.00175 
Iteration 6850/10000, Fitting loss:  0.00161 
Iteration 6860/10000, Fitting loss:  0.00153 
Iteration 6870/10000, Fitting loss:  0.00161 
Iteration 6880/10000, Fitting loss:  0.00164 
Iteration 6890/10000, Fitting loss:  0.00162 
Iteration 6900/10000, Fitting loss:  0.00177 
Iteration 6910/10000, Fitting loss:  0.00157 
Iteration 6920/10000, Fitting loss:  0.00171 
Iteration 6930/10000, Fitting loss:  0.00158 
Iteration 6940/10000, Fitting loss:  0.00159 
Iteration 6950/10000, Fitting loss:  0.00159 
Iteration 6960/10000, Fitting loss:  0.00155 
Iteration 6970/10000, Fitting loss:  0.00154 
Iteration 6980/10000, Fitting loss:  0.00167 
Iteration 6990/10000, Fitting loss:  0.00161 
Iteration 7000/10000, Fitting loss:  0.00166 
Iteration 7010/10000, Fitting loss:  0.00171 
Iteration 7020/10000, Fitting loss:  0.00162 
Iteration 7030/10000, Fitting loss:  0.00162 
Iteration 7040/10000, Fitting loss:  0.00156 
Iteration 7050/10000, Fitting loss:  0.00164 
Iteration 7060/10000, Fitting loss:  0.00171 
Iteration 7070/10000, Fitting loss:  0.00158 
Iteration 7080/10000, Fitting loss:  0.00162 
Iteration 7090/10000, Fitting loss:  0.00168 
Iteration 7100/10000, Fitting loss:  0.00159 
Iteration 7110/10000, Fitting loss:  0.00162 
Iteration 7120/10000, Fitting loss:  0.00174 
Iteration 7130/10000, Fitting loss:  0.00159 
Iteration 7140/10000, Fitting loss:  0.00164 
Iteration 7150/10000, Fitting loss:  0.00163 
Iteration 7160/10000, Fitting loss:  0.00169 
Iteration 7170/10000, Fitting loss:  0.00159 
Iteration 7180/10000, Fitting loss:  0.00172 
Iteration 7190/10000, Fitting loss:  0.00167 
Iteration 7200/10000, Fitting loss:  0.00153 
Iteration 7210/10000, Fitting loss:  0.00160 
Iteration 7220/10000, Fitting loss:  0.00164 
Iteration 7230/10000, Fitting loss:  0.00157 
Iteration 7240/10000, Fitting loss:  0.00153 
Iteration 7250/10000, Fitting loss:  0.00165 
Iteration 7260/10000, Fitting loss:  0.00152 
Iteration 7270/10000, Fitting loss:  0.00168 
Iteration 7280/10000, Fitting loss:  0.00168 
Iteration 7290/10000, Fitting loss:  0.00152 
Iteration 7300/10000, Fitting loss:  0.00167 
Iteration 7310/10000, Fitting loss:  0.00156 
Iteration 7320/10000, Fitting loss:  0.00164 
Iteration 7330/10000, Fitting loss:  0.00166 
Iteration 7340/10000, Fitting loss:  0.00160 
Iteration 7350/10000, Fitting loss:  0.00162 
Iteration 7360/10000, Fitting loss:  0.00171 
Iteration 7370/10000, Fitting loss:  0.00146 
Iteration 7380/10000, Fitting loss:  0.00167 
Iteration 7390/10000, Fitting loss:  0.00154 
Iteration 7400/10000, Fitting loss:  0.00164 
Iteration 7410/10000, Fitting loss:  0.00165 
Iteration 7420/10000, Fitting loss:  0.00161 
Iteration 7430/10000, Fitting loss:  0.00155 
Iteration 7440/10000, Fitting loss:  0.00165 
Iteration 7450/10000, Fitting loss:  0.00161 
Iteration 7460/10000, Fitting loss:  0.00158 
Iteration 7470/10000, Fitting loss:  0.00157 
Iteration 7480/10000, Fitting loss:  0.00160 
Iteration 7490/10000, Fitting loss:  0.00155 
Iteration 7500/10000, Fitting loss:  0.00163 
Iteration 7510/10000, Fitting loss:  0.00148 
Iteration 7520/10000, Fitting loss:  0.00164 
Iteration 7530/10000, Fitting loss:  0.00158 
Iteration 7540/10000, Fitting loss:  0.00160 
Iteration 7550/10000, Fitting loss:  0.00157 
Iteration 7560/10000, Fitting loss:  0.00171 
Iteration 7570/10000, Fitting loss:  0.00166 
Iteration 7580/10000, Fitting loss:  0.00167 
Iteration 7590/10000, Fitting loss:  0.00148 
Iteration 7600/10000, Fitting loss:  0.00156 
Iteration 7610/10000, Fitting loss:  0.00165 
Iteration 7620/10000, Fitting loss:  0.00155 
Iteration 7630/10000, Fitting loss:  0.00150 
Iteration 7640/10000, Fitting loss:  0.00158 
Iteration 7650/10000, Fitting loss:  0.00160 
Iteration 7660/10000, Fitting loss:  0.00161 
Iteration 7670/10000, Fitting loss:  0.00168 
Iteration 7680/10000, Fitting loss:  0.00168 
Iteration 7690/10000, Fitting loss:  0.00168 
Iteration 7700/10000, Fitting loss:  0.00162 
Iteration 7710/10000, Fitting loss:  0.00167 
Iteration 7720/10000, Fitting loss:  0.00172 
Iteration 7730/10000, Fitting loss:  0.00161 
Iteration 7740/10000, Fitting loss:  0.00171 
Iteration 7750/10000, Fitting loss:  0.00160 
Iteration 7760/10000, Fitting loss:  0.00155 
Iteration 7770/10000, Fitting loss:  0.00162 
Iteration 7780/10000, Fitting loss:  0.00160 
Iteration 7790/10000, Fitting loss:  0.00146 
Iteration 7800/10000, Fitting loss:  0.00165 
Iteration 7810/10000, Fitting loss:  0.00162 
Iteration 7820/10000, Fitting loss:  0.00156 
Iteration 7830/10000, Fitting loss:  0.00160 
Iteration 7840/10000, Fitting loss:  0.00163 
Iteration 7850/10000, Fitting loss:  0.00162 
Iteration 7860/10000, Fitting loss:  0.00172 
Iteration 7870/10000, Fitting loss:  0.00159 
Iteration 7880/10000, Fitting loss:  0.00169 
Iteration 7890/10000, Fitting loss:  0.00159 
Iteration 7900/10000, Fitting loss:  0.00167 
Iteration 7910/10000, Fitting loss:  0.00154 
Iteration 7920/10000, Fitting loss:  0.00176 
Iteration 7930/10000, Fitting loss:  0.00164 
Iteration 7940/10000, Fitting loss:  0.00159 
Iteration 7950/10000, Fitting loss:  0.00159 
Iteration 7960/10000, Fitting loss:  0.00168 
Iteration 7970/10000, Fitting loss:  0.00159 
Iteration 7980/10000, Fitting loss:  0.00162 
Iteration 7990/10000, Fitting loss:  0.00159 
Iteration 8000/10000, Fitting loss:  0.00162 
Iteration 8010/10000, Fitting loss:  0.00169 
Iteration 8020/10000, Fitting loss:  0.00164 
Iteration 8030/10000, Fitting loss:  0.00169 
Iteration 8040/10000, Fitting loss:  0.00169 
Iteration 8050/10000, Fitting loss:  0.00165 
Iteration 8060/10000, Fitting loss:  0.00160 
Iteration 8070/10000, Fitting loss:  0.00155 
Iteration 8080/10000, Fitting loss:  0.00172 
Iteration 8090/10000, Fitting loss:  0.00161 
Iteration 8100/10000, Fitting loss:  0.00177 
Iteration 8110/10000, Fitting loss:  0.00167 
Iteration 8120/10000, Fitting loss:  0.00169 
Iteration 8130/10000, Fitting loss:  0.00158 
Iteration 8140/10000, Fitting loss:  0.00155 
Iteration 8150/10000, Fitting loss:  0.00159 
Iteration 8160/10000, Fitting loss:  0.00159 
Iteration 8170/10000, Fitting loss:  0.00157 
Iteration 8180/10000, Fitting loss:  0.00169 
Iteration 8190/10000, Fitting loss:  0.00162 
Iteration 8200/10000, Fitting loss:  0.00164 
Iteration 8210/10000, Fitting loss:  0.00158 
Iteration 8220/10000, Fitting loss:  0.00157 
Iteration 8230/10000, Fitting loss:  0.00163 
Iteration 8240/10000, Fitting loss:  0.00168 
Iteration 8250/10000, Fitting loss:  0.00157 
Iteration 8260/10000, Fitting loss:  0.00160 
Iteration 8270/10000, Fitting loss:  0.00161 
Iteration 8280/10000, Fitting loss:  0.00154 
Iteration 8290/10000, Fitting loss:  0.00148 
Iteration 8300/10000, Fitting loss:  0.00160 
Iteration 8310/10000, Fitting loss:  0.00162 
Iteration 8320/10000, Fitting loss:  0.00166 
Iteration 8330/10000, Fitting loss:  0.00176 
Iteration 8340/10000, Fitting loss:  0.00171 
Iteration 8350/10000, Fitting loss:  0.00162 
Iteration 8360/10000, Fitting loss:  0.00150 
Iteration 8370/10000, Fitting loss:  0.00160 
Iteration 8380/10000, Fitting loss:  0.00163 
Iteration 8390/10000, Fitting loss:  0.00147 
Iteration 8400/10000, Fitting loss:  0.00157 
Iteration 8410/10000, Fitting loss:  0.00165 
Iteration 8420/10000, Fitting loss:  0.00156 
Iteration 8430/10000, Fitting loss:  0.00166 
Iteration 8440/10000, Fitting loss:  0.00158 
Iteration 8450/10000, Fitting loss:  0.00161 
Iteration 8460/10000, Fitting loss:  0.00164 
Iteration 8470/10000, Fitting loss:  0.00158 
Iteration 8480/10000, Fitting loss:  0.00164 
Iteration 8490/10000, Fitting loss:  0.00147 
Iteration 8500/10000, Fitting loss:  0.00167 
Iteration 8510/10000, Fitting loss:  0.00169 
Iteration 8520/10000, Fitting loss:  0.00167 
Iteration 8530/10000, Fitting loss:  0.00171 
Iteration 8540/10000, Fitting loss:  0.00160 
Iteration 8550/10000, Fitting loss:  0.00161 
Iteration 8560/10000, Fitting loss:  0.00161 
Iteration 8570/10000, Fitting loss:  0.00169 
Iteration 8580/10000, Fitting loss:  0.00164 
Iteration 8590/10000, Fitting loss:  0.00162 
Iteration 8600/10000, Fitting loss:  0.00158 
Iteration 8610/10000, Fitting loss:  0.00155 
Iteration 8620/10000, Fitting loss:  0.00167 
Iteration 8630/10000, Fitting loss:  0.00163 
Iteration 8640/10000, Fitting loss:  0.00155 
Iteration 8650/10000, Fitting loss:  0.00162 
Iteration 8660/10000, Fitting loss:  0.00169 
Iteration 8670/10000, Fitting loss:  0.00157 
Iteration 8680/10000, Fitting loss:  0.00152 
Iteration 8690/10000, Fitting loss:  0.00155 
Iteration 8700/10000, Fitting loss:  0.00160 
Iteration 8710/10000, Fitting loss:  0.00155 
Iteration 8720/10000, Fitting loss:  0.00153 
Iteration 8730/10000, Fitting loss:  0.00159 
Iteration 8740/10000, Fitting loss:  0.00164 
Iteration 8750/10000, Fitting loss:  0.00153 
Iteration 8760/10000, Fitting loss:  0.00163 
Iteration 8770/10000, Fitting loss:  0.00152 
Iteration 8780/10000, Fitting loss:  0.00167 
Iteration 8790/10000, Fitting loss:  0.00161 
Iteration 8800/10000, Fitting loss:  0.00171 
Iteration 8810/10000, Fitting loss:  0.00163 
Iteration 8820/10000, Fitting loss:  0.00164 
Iteration 8830/10000, Fitting loss:  0.00158 
Iteration 8840/10000, Fitting loss:  0.00150 
Iteration 8850/10000, Fitting loss:  0.00160 
Iteration 8860/10000, Fitting loss:  0.00156 
Iteration 8870/10000, Fitting loss:  0.00162 
Iteration 8880/10000, Fitting loss:  0.00155 
Iteration 8890/10000, Fitting loss:  0.00160 
Iteration 8900/10000, Fitting loss:  0.00159 
Iteration 8910/10000, Fitting loss:  0.00155 
Iteration 8920/10000, Fitting loss:  0.00147 
Iteration 8930/10000, Fitting loss:  0.00163 
Iteration 8940/10000, Fitting loss:  0.00162 
Iteration 8950/10000, Fitting loss:  0.00162 
Iteration 8960/10000, Fitting loss:  0.00171 
Iteration 8970/10000, Fitting loss:  0.00153 
Iteration 8980/10000, Fitting loss:  0.00157 
Iteration 8990/10000, Fitting loss:  0.00162 
Iteration 9000/10000, Fitting loss:  0.00158 
Iteration 9010/10000, Fitting loss:  0.00159 
Iteration 9020/10000, Fitting loss:  0.00159 
Iteration 9030/10000, Fitting loss:  0.00160 
Iteration 9040/10000, Fitting loss:  0.00161 
Iteration 9050/10000, Fitting loss:  0.00162 
Iteration 9060/10000, Fitting loss:  0.00164 
Iteration 9070/10000, Fitting loss:  0.00157 
Iteration 9080/10000, Fitting loss:  0.00155 
Iteration 9090/10000, Fitting loss:  0.00157 
Iteration 9100/10000, Fitting loss:  0.00155 
Iteration 9110/10000, Fitting loss:  0.00162 
Iteration 9120/10000, Fitting loss:  0.00164 
Iteration 9130/10000, Fitting loss:  0.00156 
Iteration 9140/10000, Fitting loss:  0.00159 
Iteration 9150/10000, Fitting loss:  0.00159 
Iteration 9160/10000, Fitting loss:  0.00158 
Iteration 9170/10000, Fitting loss:  0.00166 
Iteration 9180/10000, Fitting loss:  0.00159 
Iteration 9190/10000, Fitting loss:  0.00159 
Iteration 9200/10000, Fitting loss:  0.00159 
Iteration 9210/10000, Fitting loss:  0.00159 
Iteration 9220/10000, Fitting loss:  0.00160 
Iteration 9230/10000, Fitting loss:  0.00172 
Iteration 9240/10000, Fitting loss:  0.00152 
Iteration 9250/10000, Fitting loss:  0.00162 
Iteration 9260/10000, Fitting loss:  0.00158 
Iteration 9270/10000, Fitting loss:  0.00160 
Iteration 9280/10000, Fitting loss:  0.00168 
Iteration 9290/10000, Fitting loss:  0.00172 
Iteration 9300/10000, Fitting loss:  0.00162 
Iteration 9310/10000, Fitting loss:  0.00159 
Iteration 9320/10000, Fitting loss:  0.00153 
Iteration 9330/10000, Fitting loss:  0.00157 
Iteration 9340/10000, Fitting loss:  0.00156 
Iteration 9350/10000, Fitting loss:  0.00155 
Iteration 9360/10000, Fitting loss:  0.00159 
Iteration 9370/10000, Fitting loss:  0.00161 
Iteration 9380/10000, Fitting loss:  0.00157 
Iteration 9390/10000, Fitting loss:  0.00163 
Iteration 9400/10000, Fitting loss:  0.00155 
Iteration 9410/10000, Fitting loss:  0.00167 
Iteration 9420/10000, Fitting loss:  0.00154 
Iteration 9430/10000, Fitting loss:  0.00167 
Iteration 9440/10000, Fitting loss:  0.00161 
Iteration 9450/10000, Fitting loss:  0.00156 
Iteration 9460/10000, Fitting loss:  0.00155 
Iteration 9470/10000, Fitting loss:  0.00155 
Iteration 9480/10000, Fitting loss:  0.00161 
Iteration 9490/10000, Fitting loss:  0.00166 
Iteration 9500/10000, Fitting loss:  0.00158 
Iteration 9510/10000, Fitting loss:  0.00166 
Iteration 9520/10000, Fitting loss:  0.00157 
Iteration 9530/10000, Fitting loss:  0.00149 
Iteration 9540/10000, Fitting loss:  0.00160 
Iteration 9550/10000, Fitting loss:  0.00164 
Iteration 9560/10000, Fitting loss:  0.00155 
Iteration 9570/10000, Fitting loss:  0.00160 
Iteration 9580/10000, Fitting loss:  0.00159 
Iteration 9590/10000, Fitting loss:  0.00167 
Iteration 9600/10000, Fitting loss:  0.00153 
Iteration 9610/10000, Fitting loss:  0.00163 
Iteration 9620/10000, Fitting loss:  0.00161 
Iteration 9630/10000, Fitting loss:  0.00161 
Iteration 9640/10000, Fitting loss:  0.00156 
Iteration 9650/10000, Fitting loss:  0.00167 
Iteration 9660/10000, Fitting loss:  0.00169 
Iteration 9670/10000, Fitting loss:  0.00158 
Iteration 9680/10000, Fitting loss:  0.00167 
Iteration 9690/10000, Fitting loss:  0.00159 
Iteration 9700/10000, Fitting loss:  0.00157 
Iteration 9710/10000, Fitting loss:  0.00158 
Iteration 9720/10000, Fitting loss:  0.00158 
Iteration 9730/10000, Fitting loss:  0.00167 
Iteration 9740/10000, Fitting loss:  0.00153 
Iteration 9750/10000, Fitting loss:  0.00160 
Iteration 9760/10000, Fitting loss:  0.00163 
Iteration 9770/10000, Fitting loss:  0.00161 
Iteration 9780/10000, Fitting loss:  0.00155 
Iteration 9790/10000, Fitting loss:  0.00161 
Iteration 9800/10000, Fitting loss:  0.00170 
Iteration 9810/10000, Fitting loss:  0.00174 
Iteration 9820/10000, Fitting loss:  0.00156 
Iteration 9830/10000, Fitting loss:  0.00160 
Iteration 9840/10000, Fitting loss:  0.00163 
Iteration 9850/10000, Fitting loss:  0.00154 
Iteration 9860/10000, Fitting loss:  0.00160 
Iteration 9870/10000, Fitting loss:  0.00164 
Iteration 9880/10000, Fitting loss:  0.00163 
Iteration 9890/10000, Fitting loss:  0.00164 
Iteration 9900/10000, Fitting loss:  0.00164 
Iteration 9910/10000, Fitting loss:  0.00154 
Iteration 9920/10000, Fitting loss:  0.00158 
Iteration 9930/10000, Fitting loss:  0.00162 
Iteration 9940/10000, Fitting loss:  0.00162 
Iteration 9950/10000, Fitting loss:  0.00161 
Iteration 9960/10000, Fitting loss:  0.00160 
Iteration 9970/10000, Fitting loss:  0.00158 
Iteration 9980/10000, Fitting loss:  0.00153 
Iteration 9990/10000, Fitting loss:  0.00151 
